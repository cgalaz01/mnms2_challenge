{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnms2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR3CyUbArjx_"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNYn7f2Uj_hn"
      },
      "source": [
        "!pip install SimpleITK\n",
        "!pip install voxelmorph\n",
        "#!pip install tensorflow==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avY2iXtLo2LU"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v144Jhl6nrCW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQuyQsYoJcL"
      },
      "source": [
        "# Change to the location of the preprocessed data (data_cache)\n",
        "data_zip_path = '/content/gdrive/MyDrive/mnms2_challenge/data_cache.zip'    # Example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDYBLbSVzUQY"
      },
      "source": [
        "Copy data from google drive to Colab session (slightly slow process)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_RthMEAzX21"
      },
      "source": [
        "!cp \"{data_zip_path}\" .\n",
        "!unzip -q data_cache.zip\n",
        "!rm data_cache.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT7nJbC_0q63"
      },
      "source": [
        "# session path\n",
        "path_to_data_cache = '/content/data_cache/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQEHJBWjnXO"
      },
      "source": [
        "src/data/preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nV-OcItjukm"
      },
      "source": [
        "from typing import List, Union, Tuple\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "\n",
        "import SimpleITK as sitk\n",
        "\n",
        "\n",
        "class Preprocess():\n",
        "    \n",
        "    @staticmethod\n",
        "    def resample_image(image: sitk.Image, out_spacing: Tuple[float]=(1.0, 1.0, 1.0),\n",
        "                       out_size: Union[None, Tuple[int]]=None, is_label: bool=False,\n",
        "                       pad_value: float=0) -> sitk.Image:\n",
        "        original_spacing = np.array(image.GetSpacing())\n",
        "        original_size = np.array(image.GetSize())\n",
        "        \n",
        "        if original_size[-1] == 1:\n",
        "            out_spacing = list(out_spacing)\n",
        "            out_spacing[-1] = original_spacing[-1]\n",
        "            out_spacing = tuple(out_spacing)\n",
        "    \n",
        "        if out_size is None:\n",
        "            out_size = np.round(np.array(original_size * original_spacing / np.array(out_spacing))).astype(int)\n",
        "        else:\n",
        "            out_size = np.array(out_size)\n",
        "    \n",
        "        original_direction = np.array(image.GetDirection()).reshape(len(original_spacing),-1)\n",
        "        original_center = (np.array(original_size, dtype=float) - 1.0) / 2.0 * original_spacing\n",
        "        out_center = (np.array(out_size, dtype=float) - 1.0) / 2.0 * np.array(out_spacing)\n",
        "    \n",
        "        original_center = np.matmul(original_direction, original_center)\n",
        "        out_center = np.matmul(original_direction, out_center)\n",
        "        out_origin = np.array(image.GetOrigin()) + (original_center - out_center)\n",
        "    \n",
        "        resample = sitk.ResampleImageFilter()\n",
        "        resample.SetOutputSpacing(out_spacing)\n",
        "        resample.SetSize(out_size.tolist())\n",
        "        resample.SetOutputDirection(image.GetDirection())\n",
        "        resample.SetOutputOrigin(out_origin.tolist())\n",
        "        resample.SetTransform(sitk.Transform())\n",
        "        resample.SetDefaultPixelValue(pad_value)\n",
        "    \n",
        "        if is_label:\n",
        "            resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
        "        else:\n",
        "            resample.SetInterpolator(sitk.sitkBSpline)\n",
        "    \n",
        "        return resample.Execute(image)\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def normalise_intensities(image: sitk.Image) -> sitk.Image:\n",
        "        # Normalise image fro hypothetical 0-500 to 0-1 range\n",
        "        normalised_image = sitk.Cast(image, sitk.sitkFloat32) / 500.0\n",
        "        \n",
        "        return normalised_image\n",
        "    \n",
        "    \n",
        "\n",
        "class Registration():\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def _function_register(initial_transform, moving_image, fixed_image,\n",
        "                           learning_rate, histogram_bins, sampling_rate,\n",
        "                           seed) -> Tuple[sitk.Transform, float]:\n",
        "    \n",
        "        sitk.ProcessObject.SetGlobalDefaultNumberOfThreads(1)\n",
        "        registration_method = sitk.ImageRegistrationMethod()\n",
        "            \n",
        "        # Similarity metric settings.\n",
        "        registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=histogram_bins)\n",
        "        registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
        "        registration_method.SetMetricSamplingPercentage(sampling_rate, seed=seed)\n",
        "        \n",
        "        registration_method.SetInterpolator(sitk.sitkLinear)\n",
        "        \n",
        "        # Optimizer settings.\n",
        "        if learning_rate == None:\n",
        "            estimate_learning_rate = registration_method.EachIteration\n",
        "            learning_rate = 0\n",
        "        else:\n",
        "            estimate_learning_rate = registration_method.Never\n",
        "            \n",
        "        registration_method.SetOptimizerAsGradientDescent(learningRate=learning_rate,\n",
        "                                                          numberOfIterations=100,\n",
        "                                                          convergenceMinimumValue=1e-12,\n",
        "                                                          convergenceWindowSize=10,\n",
        "                                                          estimateLearningRate=estimate_learning_rate)\n",
        "    \n",
        "        registration_method.SetOptimizerScalesFromPhysicalShift()\n",
        "        \n",
        "        registration_method.SetInitialTransform(initial_transform, inPlace=True)        \n",
        "        \n",
        "        transform = registration_method.Execute(sitk.Cast(fixed_image, sitk.sitkFloat32), \n",
        "                                                sitk.Cast(moving_image, sitk.sitkFloat32))\n",
        "        \n",
        "        \n",
        "        return transform, registration_method.GetMetricValue()\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def _parallel_register(initial_transform, moving_image, fixed_image,\n",
        "                           learning_rate_list, histogram_bins, sampling_rate,\n",
        "                           seed) -> Tuple[sitk.Transform, float]:\n",
        "        \n",
        "        function_input = [(sitk.AffineTransform(initial_transform),\n",
        "                           moving_image,\n",
        "                           fixed_image,\n",
        "                           learning_rate_list[i],\n",
        "                           histogram_bins,\n",
        "                           sampling_rate,\n",
        "                           seed) for i in range(len(learning_rate_list))]\n",
        "        \n",
        "        with Pool() as pool:\n",
        "            output_results = pool.starmap(Registration._function_register, function_input)\n",
        "\n",
        "        selected_transform = None\n",
        "        min_metric_value = 1e5\n",
        "        for i in range(len(output_results)):\n",
        "            transform, metric_value = output_results[i]\n",
        "            if metric_value < min_metric_value:\n",
        "                min_metric_value = metric_value\n",
        "                selected_transform = transform\n",
        "                \n",
        "        return selected_transform, min_metric_value\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def _major_alignment(moving_image: sitk.Image, fixed_image: sitk.Image,\n",
        "                         debug_output: int=0) -> Tuple[sitk.Transform, float]:\n",
        "        debug_image_outputs = []\n",
        "        debug_image_moving = []\n",
        "        debug_image_fixed = []\n",
        "        \n",
        "        sitk.ProcessObject.SetGlobalDefaultNumberOfThreads(1)\n",
        "        \n",
        "        initial_transform = sitk.AffineTransform(3)\n",
        "        \n",
        "        if debug_output > 0:\n",
        "            debug_image = sitk.Resample(moving_image,\n",
        "                                        fixed_image,\n",
        "                                        initial_transform,\n",
        "                                        sitk.sitkLinear,\n",
        "                                        0.0,\n",
        "                                        moving_image.GetPixelID())\n",
        "            debug_image_moving.append(debug_image)\n",
        "            debug_image_fixed.append(fixed_image)\n",
        "        \n",
        "        \n",
        "        transform = initial_transform\n",
        "        \n",
        "        \n",
        "        gaussian_sigma = [8, 4, 2, 1, 0]\n",
        "        \n",
        "        histogram_bins = 200\n",
        "        learning_rate_list = [[8.0, 4.0, 2.0, 1.0, None],\n",
        "                              [4.0, 2.0, 1.0, 0.5, None],\n",
        "                              [2.0, 1.0, 0.5, 0.25, None],\n",
        "                              [1.0, 0.5, 0.25, 0.1, None],\n",
        "                              [0.5, 0.25, 0.1, 0.05, None]]\n",
        "        sampling_rate = 1.0\n",
        "        \n",
        "        seed = 12453\n",
        "        \n",
        "        for i in range(len(gaussian_sigma)):\n",
        "                \n",
        "            numpy_fixed_image = sitk.GetArrayFromImage(fixed_image)    \n",
        "            numpy_fixed_image = ndimage.gaussian_filter(numpy_fixed_image,\n",
        "                                                        sigma=(1,\n",
        "                                                               gaussian_sigma[i],\n",
        "                                                               gaussian_sigma[i]),\n",
        "                                                        mode='constant')\n",
        "            \n",
        "            \n",
        "            tmp_fixed_image = sitk.GetImageFromArray(numpy_fixed_image)\n",
        "            tmp_fixed_image.CopyInformation(fixed_image)\n",
        "            \n",
        "            numpy_moving_image = sitk.GetArrayFromImage(moving_image)\n",
        "            numpy_moving_image = ndimage.gaussian_filter(numpy_moving_image,\n",
        "                                                         sigma=(gaussian_sigma[i] / 2,\n",
        "                                                                gaussian_sigma[i],\n",
        "                                                                gaussian_sigma[i]),\n",
        "                                                         mode='constant')\n",
        "            \n",
        "            tmp_moving_image = sitk.GetImageFromArray(numpy_moving_image)\n",
        "            tmp_moving_image.CopyInformation(moving_image)\n",
        "            \n",
        "    \n",
        "            transform, metric = Registration._parallel_register(sitk.AffineTransform(transform),\n",
        "                                                                tmp_moving_image, tmp_fixed_image,\n",
        "                                                                learning_rate_list[i], histogram_bins,\n",
        "                                                                sampling_rate, seed)\n",
        "        \n",
        "            if debug_output > 0:\n",
        "                debug_image = sitk.Resample(tmp_moving_image,\n",
        "                                            tmp_fixed_image,\n",
        "                                            transform,\n",
        "                                            sitk.sitkLinear,\n",
        "                                            0.0,\n",
        "                                            tmp_moving_image.GetPixelID())\n",
        "                debug_image_moving.append(debug_image)\n",
        "                debug_image_fixed.append(tmp_fixed_image)\n",
        "    \n",
        "    \n",
        "        \n",
        "        final_transform = transform\n",
        "        \n",
        "        debug_image_outputs = [debug_image_moving, debug_image_fixed]\n",
        "        \n",
        "        if debug_output == 1:\n",
        "            return final_transform, metric, debug_image_outputs\n",
        "        else:\n",
        "            return final_transform, metric\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def _minor_alignment(moving_image: sitk.Image, fixed_image: sitk.Image,\n",
        "                         debug_output: int=0) -> Tuple[sitk.Transform, float]:\n",
        "        debug_image_outputs = []\n",
        "        debug_image_moving = []\n",
        "        debug_image_fixed = []\n",
        "        \n",
        "        sitk.ProcessObject.SetGlobalDefaultNumberOfThreads(1)\n",
        "        \n",
        "        initial_transform = sitk.AffineTransform(3)\n",
        "        \n",
        "        if debug_output > 0:\n",
        "            debug_image = sitk.Resample(moving_image,\n",
        "                                        fixed_image,\n",
        "                                        initial_transform,\n",
        "                                        sitk.sitkLinear,\n",
        "                                        0.0,\n",
        "                                        moving_image.GetPixelID())\n",
        "            debug_image_moving.append(debug_image)\n",
        "            debug_image_fixed.append(fixed_image)\n",
        "        \n",
        "        \n",
        "        transform = initial_transform\n",
        "        \n",
        "        \n",
        "        gaussian_sigma = [2, 1, 0]\n",
        "        \n",
        "        histogram_bins = 200\n",
        "        learning_rate_list = [[2.0, 2.0, 1.0, 0.5, None],\n",
        "                              [2.0, 1.0, 0.5, 0.25, None],\n",
        "                              [1.0, 0.5, 0.25, 0.1, None],]\n",
        "        sampling_rate = 1.0\n",
        "        \n",
        "        seed =  12453\n",
        "        \n",
        "        for i in range(len(gaussian_sigma)):\n",
        "                \n",
        "            numpy_fixed_image = sitk.GetArrayFromImage(fixed_image)    \n",
        "            numpy_fixed_image = ndimage.gaussian_filter(numpy_fixed_image,\n",
        "                                                        sigma=(1,\n",
        "                                                               gaussian_sigma[i],\n",
        "                                                               gaussian_sigma[i]),\n",
        "                                                        mode='constant')\n",
        "            \n",
        "            \n",
        "            tmp_fixed_image = sitk.GetImageFromArray(numpy_fixed_image)\n",
        "            tmp_fixed_image.CopyInformation(fixed_image)\n",
        "            \n",
        "            numpy_moving_image = sitk.GetArrayFromImage(moving_image)\n",
        "            numpy_moving_image = ndimage.gaussian_filter(numpy_moving_image,\n",
        "                                                         sigma=(gaussian_sigma[i] / 2,\n",
        "                                                                gaussian_sigma[i],\n",
        "                                                                gaussian_sigma[i]),\n",
        "                                                         mode='constant')\n",
        "            \n",
        "            tmp_moving_image = sitk.GetImageFromArray(numpy_moving_image)\n",
        "            tmp_moving_image.CopyInformation(moving_image)\n",
        "    \n",
        "            transform, metric = Registration._parallel_register(sitk.AffineTransform(transform),\n",
        "                                                                tmp_moving_image, tmp_fixed_image,\n",
        "                                                                learning_rate_list[i], histogram_bins,\n",
        "                                                                sampling_rate, seed)\n",
        "        \n",
        "            if debug_output > 0:\n",
        "                debug_image = sitk.Resample(tmp_moving_image,\n",
        "                                            tmp_fixed_image,\n",
        "                                            transform,\n",
        "                                            sitk.sitkLinear,\n",
        "                                            0.0,\n",
        "                                            tmp_moving_image.GetPixelID())\n",
        "                debug_image_moving.append(debug_image)\n",
        "                debug_image_fixed.append(tmp_fixed_image)\n",
        "    \n",
        "        \n",
        "        final_transform = transform\n",
        "        \n",
        "        debug_image_outputs = [debug_image_moving, debug_image_fixed]\n",
        "        \n",
        "        if debug_output == 1:\n",
        "            return final_transform, metric, debug_image_outputs\n",
        "        else:\n",
        "            return final_transform, metric\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def register(moving_image: sitk.Image, fixed_image: sitk.Image,\n",
        "                 debug_output: int=0) -> Tuple[sitk.Transform, float, Union[None, List[List[sitk.Image]]]]:        \n",
        "        major_output = Registration._major_alignment(moving_image, fixed_image, debug_output)\n",
        "        minor_output = Registration._minor_alignment(moving_image, fixed_image, debug_output)\n",
        "\n",
        "        if major_output[1] < minor_output[1]:\n",
        "            return major_output\n",
        "        else:\n",
        "            return minor_output\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def get_affine_matrix(image: sitk.Image) -> np.ndarray:\n",
        "        # get affine transform in LPS\n",
        "        c = [image.TransformContinuousIndexToPhysicalPoint(p)\n",
        "             for p in ((1, 0, 0),\n",
        "                       (0, 1, 0),\n",
        "                       (0, 0, 1),\n",
        "                       (0, 0, 0))]\n",
        "        c = np.array(c)\n",
        "        affine = np.concatenate([\n",
        "            np.concatenate([c[0:3] - c[3:], c[3:]], axis=0),\n",
        "            [[0.], [0.], [0.], [1.]]\n",
        "        ], axis=1)\n",
        "        affine = np.transpose(affine)\n",
        "        # convert to RAS to match nibabel etc.\n",
        "        affine = np.matmul(np.diag([-1., -1., 1., 1.]), affine)\n",
        "        return affine\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def get_affine_registration_matrix(moving_image: sitk.Image,\n",
        "                                       registration_affine: sitk.Transform) -> np.ndarray:\n",
        "        # Get affine transform in LPS\n",
        "        c = [registration_affine.TransformPoint(\n",
        "                 moving_image.TransformContinuousIndexToPhysicalPoint(p))\n",
        "             for p in ((1, 0, 0),\n",
        "                       (0, 1, 0),\n",
        "                       (0, 0, 1),\n",
        "                       (0, 0, 0))]\n",
        "        c = np.array(c)\n",
        "        affine = np.concatenate([\n",
        "            np.concatenate([c[0:3] - c[3:], c[3:]], axis=0),\n",
        "            [[0.], [0.], [0.], [1.]]\n",
        "        ], axis=1)\n",
        "        affine = np.transpose(affine)\n",
        "        # Convert to RAS to match nibabel etc.\n",
        "        affine = np.matmul(np.diag([-1., -1., 1., 1.]), affine)\n",
        "        return affine\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV9KwNnkjY_V"
      },
      "source": [
        "src/data/loader.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL1GULe7jRfJ"
      },
      "source": [
        "import os\n",
        "\n",
        "from enum import Enum\n",
        "\n",
        "from typing import Any, Dict, Tuple, List, Union\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import SimpleITK as sitk\n",
        "\n",
        "\n",
        "class FileType(Enum):\n",
        "    sa_ed = 'SA_ED'\n",
        "    sa_ed_gt = 'SA_ED_gt'\n",
        "    sa_es = 'SA_ES'\n",
        "    sa_es_gt = 'SA_ES_gt'\n",
        "    la_ed = 'LA_ED'\n",
        "    la_ed_gt = 'LA_ED_gt'\n",
        "    la_es = 'LA_ES'\n",
        "    la_es_gt = 'LA_ES_gt'\n",
        "    \n",
        "    \n",
        "class ExtraType(Enum):\n",
        "    reg_affine = 'SA_to_LA_registration_affine'\n",
        "    \n",
        "\n",
        "class OutputAffine(Enum):\n",
        "    sa_affine = 'SA_Affine'\n",
        "    la_affine = 'LA_Affine'    \n",
        "    \n",
        "\n",
        "class DataGenerator():\n",
        "\n",
        "    \n",
        "    def __init__(self, floating_precision: str = '32') -> None:\n",
        "        #file_path = Path(__file__).parent.absolute()\n",
        "        #expected_data_directory = os.path.join('..', '..', 'data')\n",
        "        \n",
        "        #self.data_directory = Path(os.path.join(file_path, expected_data_directory))\n",
        "        #self.cache_directory = os.path.join('..', '..', 'data_cache')\n",
        "        #self.cache_directory = Path(os.path.join(file_path, self.cache_directory))\n",
        "        self.data_directory = path_to_data_cache\n",
        "        self.cache_directory = path_to_data_cache\n",
        "\n",
        "        self.train_directory = Path(os.path.join(self.data_directory, 'training'))\n",
        "        # For the purposes of model development, the 'validation' set is treated\n",
        "        # as the test set\n",
        "        # (It does not have ground truth - validated on submission only)\n",
        "        self.testing_directory = Path(os.path.join(self.data_directory, 'validation'))\n",
        "        \n",
        "        self.train_list = self.get_patient_list(self.train_directory)\n",
        "        self.train_list = self.randomise_list(self.train_list, seed=4516, inplace=True)\n",
        "        self.train_list, self.validation_list = self.split_list(self.train_list, split_fraction=0.8)\n",
        "        self.test_list = self.get_patient_list(self.testing_directory)\n",
        "        \n",
        "        self.target_spacing = (1.25, 1.25, 10)\n",
        "        self.target_size = (256, 256, 17)\n",
        "        \n",
        "        self.n_classes = 4  # Including background\n",
        "\n",
        "        self.floating_precision = floating_precision\n",
        "        \n",
        "        # Compute the shape for the inputs and outputs\n",
        "        self.sa_target_shape = list(self.target_size)\n",
        "        self.sa_shape = self.sa_target_shape.copy()\n",
        "        self.sa_target_shape.append(self.n_classes)\n",
        "        \n",
        "        self.la_target_shape = list(self.target_size)\n",
        "        self.la_shape = self.la_target_shape.copy()\n",
        "        self.la_shape[-1] = 1\n",
        "        self.la_target_shape[-1] = self.n_classes\n",
        "        \n",
        "        self.affine_shape = (4, 4)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_patient_list(root_directory: Union[str, Path]) -> List[Path]:\n",
        "        files = glob(os.path.join(root_directory, \"**\"))\n",
        "        files = [Path(i) for i in files]\n",
        "        \n",
        "        return files\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def randomise_list(item_list: List[Any], seed: Union[None, int]=None,\n",
        "                       inplace: bool=True) -> List[Any]:\n",
        "        if not inplace:\n",
        "            item_list = item_list.copy()\n",
        "            \n",
        "        random_generator = np.random.RandomState(seed)\n",
        "        random_generator.shuffle(item_list)\n",
        "        \n",
        "        return item_list\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def split_list(item_list: List[Any], split_fraction: float) -> Tuple[List[Any]]:\n",
        "        assert 0 < split_fraction < 1\n",
        "        \n",
        "        split_index = int(len(item_list) * split_fraction)\n",
        "        \n",
        "        split_1 = item_list[:split_index]\n",
        "        split_2 = item_list[split_index:]\n",
        "                \n",
        "        return split_1, split_2\n",
        "\n",
        "        \n",
        "    @staticmethod\n",
        "    def load_image(patient_directory: Union[str, Path], file_type: FileType) -> sitk.Image:\n",
        "        file_suffix = '*' + file_type.value + '.nii.gz'\n",
        "        \n",
        "        file_path = os.path.join(patient_directory, file_suffix)\n",
        "        file_path = glob(file_path)\n",
        "        assert len(file_path) == 1\n",
        "        file_path = file_path[0]\n",
        "        \n",
        "        sitk_image = sitk.ReadImage(file_path)\n",
        "        \n",
        "        return sitk_image\n",
        "    \n",
        "    @staticmethod\n",
        "    def load_transformation(patient_directory: Union[str, Path], file_type: ExtraType) -> sitk.Transform:\n",
        "        file_suffix = '*' + file_type.value + '.tfm'\n",
        "        \n",
        "        file_path = os.path.join(patient_directory, file_suffix)\n",
        "        file_path = glob(file_path)\n",
        "        assert len(file_path) == 1\n",
        "        file_path = file_path[0]\n",
        "        \n",
        "        sitk_transform = sitk.ReadTransform(file_path)\n",
        "        \n",
        "        return sitk_transform\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def load_patient_data(patient_directory: Union[str, Path], has_gt: bool = True) -> Dict[str, sitk.Image]:\n",
        "        patient_data = {}\n",
        "        \n",
        "        patient_data[FileType.sa_ed.value] = DataGenerator.load_image(patient_directory, FileType.sa_ed)        \n",
        "        patient_data[FileType.sa_es.value] = DataGenerator.load_image(patient_directory, FileType.sa_es)        \n",
        "        patient_data[FileType.la_ed.value] = DataGenerator.load_image(patient_directory, FileType.la_ed)\n",
        "        patient_data[FileType.la_es.value] = DataGenerator.load_image(patient_directory, FileType.la_es)\n",
        "        \n",
        "        if has_gt:\n",
        "            patient_data[FileType.sa_ed_gt.value] = DataGenerator.load_image(patient_directory, FileType.sa_ed_gt)\n",
        "            patient_data[FileType.sa_es_gt.value] = DataGenerator.load_image(patient_directory, FileType.sa_es_gt)\n",
        "            patient_data[FileType.la_ed_gt.value] = DataGenerator.load_image(patient_directory, FileType.la_ed_gt)\n",
        "            patient_data[FileType.la_es_gt.value] = DataGenerator.load_image(patient_directory, FileType.la_es_gt)\n",
        "            \n",
        "        \n",
        "        return patient_data\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def load_extra_patient_data(patient_directory: Union[str, Path],\n",
        "                                patient_data: Dict[str, sitk.Image]) -> Dict[str, sitk.Image]:\n",
        "        \n",
        "        patient_data[ExtraType.reg_affine.value] = DataGenerator.load_transformation(patient_directory,\n",
        "                                                                                     ExtraType.reg_affine)\n",
        "        \n",
        "        return patient_data\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def preprocess_patient_data(patient_data: Dict[str, sitk.Image], spacing: Tuple[float],\n",
        "                                size: Tuple[int], has_gt: bool = True, register: bool = True) -> Dict[str, sitk.Image]:\n",
        "        # Resample images to standardised spacing and size\n",
        "        # Short-axis\n",
        "        patient_data[FileType.sa_ed.value] = Preprocess.resample_image(patient_data[FileType.sa_ed.value],\n",
        "                                                                       spacing, size, is_label=False)\n",
        "        patient_data[FileType.sa_es.value] = Preprocess.resample_image(patient_data[FileType.sa_es.value],\n",
        "                                                                       spacing, size, is_label=False)\n",
        "        if has_gt:\n",
        "            patient_data[FileType.sa_ed_gt.value] = Preprocess.resample_image(patient_data[FileType.sa_ed_gt.value],\n",
        "                                                                              spacing, size, is_label=True)\n",
        "            patient_data[FileType.sa_es_gt.value] = Preprocess.resample_image(patient_data[FileType.sa_es_gt.value],\n",
        "                                                                              spacing, size, is_label=True)\n",
        "\n",
        "        # Long-axis\n",
        "        la_spacing = list(spacing)\n",
        "        la_spacing[2] = patient_data[FileType.la_ed.value].GetSpacing()[2]\n",
        "        la_size = list(size)\n",
        "        la_size[2] = 1\n",
        "        patient_data[FileType.la_ed.value] = Preprocess.resample_image(patient_data[FileType.la_ed.value],\n",
        "                                                                       la_spacing, la_size, is_label=False)\n",
        "        patient_data[FileType.la_es.value] = Preprocess.resample_image(patient_data[FileType.la_es.value],\n",
        "                                                                       la_spacing, la_size, is_label=False)\n",
        "        if has_gt:\n",
        "            patient_data[FileType.la_ed_gt.value] = Preprocess.resample_image(patient_data[FileType.la_ed_gt.value],\n",
        "                                                                              la_spacing, la_size, is_label=True)\n",
        "            patient_data[FileType.la_es_gt.value] = Preprocess.resample_image(patient_data[FileType.la_es_gt.value],\n",
        "                                                                              la_spacing, la_size, is_label=True)\n",
        "        \n",
        "        # Register short-axis to long axis (only for end diastolic for faster execution time)\n",
        "        if register:\n",
        "            affine_transform, _ = Registration.register(patient_data[FileType.sa_ed.value],\n",
        "                                                        patient_data[FileType.la_ed.value])\n",
        "            patient_data[ExtraType.reg_affine.value] = affine_transform\n",
        "        \n",
        "        # Normalise intensities so there are (roughly) [0-1]\n",
        "        patient_data[FileType.sa_ed.value] = Preprocess.normalise_intensities(patient_data[FileType.sa_ed.value])\n",
        "        patient_data[FileType.sa_es.value] = Preprocess.normalise_intensities(patient_data[FileType.sa_es.value])\n",
        "        \n",
        "        patient_data[FileType.la_ed.value] = Preprocess.normalise_intensities(patient_data[FileType.la_ed.value])\n",
        "        patient_data[FileType.la_es.value] = Preprocess.normalise_intensities(patient_data[FileType.la_es.value])\n",
        "        \n",
        "        return patient_data\n",
        "        \n",
        "\n",
        "    def get_cache_directory(self, patient_directory: Union[str, Path]) -> Path:\n",
        "        path = os.path.normpath(patient_directory)\n",
        "        split_path = path.split(os.sep)\n",
        "        # .. / data / training or vlaidation / patient ID\n",
        "        # only last two are of interest\n",
        "        cache_directory = Path(os.path.join(self.cache_directory,\n",
        "                                            split_path[-2],\n",
        "                                            split_path[-1]))\n",
        "        \n",
        "        return cache_directory\n",
        "\n",
        "    \n",
        "    def is_cached(self, patient_directory: Union[str, Path], has_gt: bool = True) -> bool:\n",
        "        patient_cache_directory = self.get_cache_directory(patient_directory)\n",
        "        \n",
        "        # Check if folder exists\n",
        "        if os.path.isdir(patient_cache_directory):\n",
        "            # and every individual file exist\n",
        "            for expected_file_name in FileType:\n",
        "                if not has_gt and expected_file_name.value.endswith('_gt'):\n",
        "                    continue\n",
        "                expected_file_path = os.path.join(patient_cache_directory,\n",
        "                                                  expected_file_name.value + '.nii.gz')\n",
        "                if not os.path.exists(expected_file_path):\n",
        "                    return False\n",
        "                \n",
        "            for expected_file_name in ExtraType:\n",
        "                expected_file_path = os.path.join(patient_cache_directory,\n",
        "                                                  expected_file_name.value + '.tfm')\n",
        "                if not os.path.exists(expected_file_path):\n",
        "                    return False\n",
        "            return True\n",
        "        \n",
        "        return False\n",
        "\n",
        "        \n",
        "    def save_cache(self, patient_directory: Union[str, Path],\n",
        "                    patient_data: Dict[str, sitk.Image]) -> None:\n",
        "        patient_cache_directory = self.get_cache_directory(patient_directory)\n",
        "        os.makedirs(patient_cache_directory, exist_ok=True)\n",
        "        \n",
        "        for key, data in patient_data.items():\n",
        "            if key in (k.value for k in FileType):\n",
        "                file_path = os.path.join(patient_cache_directory, key + '.nii.gz')\n",
        "                sitk.WriteImage(data, file_path)\n",
        "            elif key in (k.value for k in ExtraType):\n",
        "                file_path = os.path.join(patient_cache_directory, key + '.tfm')\n",
        "                sitk.WriteTransform(data, file_path)\n",
        "        \n",
        "    \n",
        "    def load_cache(self, patient_directory: Union[str, Path], has_gt: bool = True) -> Dict[str, sitk.Image]:\n",
        "        patient_cache_directory = self.get_cache_directory(patient_directory)\n",
        "        patient_data = self.load_patient_data(patient_cache_directory, has_gt)\n",
        "        patient_data = self.load_extra_patient_data(patient_cache_directory, patient_data)\n",
        "        \n",
        "        return patient_data\n",
        "    \n",
        "    \n",
        "    def to_numpy(self, patient_data: Dict[str, sitk.Image]) -> Dict[str, np.ndarray]:\n",
        "        \n",
        "        # Handle 'ExtraType' data first\n",
        "        sa_affine = Registration.get_affine_registration_matrix(patient_data[FileType.sa_ed.value],\n",
        "                                                                patient_data[ExtraType.reg_affine.value])\n",
        "        sa_affine = sa_affine.astype(np.float32)\n",
        "        la_affine = Registration.get_affine_matrix(patient_data[FileType.la_ed.value])\n",
        "        la_affine = la_affine.astype(np.float32)\n",
        "        \n",
        "        # Free from memory (and indexing)\n",
        "        del patient_data[ExtraType.reg_affine.value]\n",
        "        \n",
        "        # Handle original file data (images and segmentations)\n",
        "        for key, image in patient_data.items():\n",
        "            numpy_image = sitk.GetArrayFromImage(image)\n",
        "            # Swap axes so ordering is x, y, z rather than z, y, x as stored\n",
        "            # in sitk\n",
        "            numpy_image = np.swapaxes(numpy_image, 0, -1)\n",
        "            \n",
        "            # Generate one-hot encoding of the labels\n",
        "            if 'gt' in key:\n",
        "                numpy_image = numpy_image.astype(np.uint8)\n",
        "                if 'LA' in key: # use the 'depth; axis as the channel for the label\n",
        "                    numpy_image = np.squeeze(numpy_image, axis=-1)\n",
        "                n_values = self.n_classes\n",
        "                numpy_image = np.eye(n_values)[numpy_image]\n",
        "            \n",
        "            \n",
        "            if self.floating_precision == '16':\n",
        "                numpy_image = numpy_image.astype(np.float16)\n",
        "            else:\n",
        "                numpy_image = numpy_image.astype(np.float32)\n",
        "                \n",
        "            # Add 'channel' axis for 3D images\n",
        "            #if 'sa' in key:\n",
        "            #    numpy_image = np.expand_dims(numpy_image, axis=-1)\n",
        "                \n",
        "            patient_data[key] = numpy_image\n",
        "        \n",
        "        patient_data[OutputAffine.sa_affine.value] = sa_affine\n",
        "        patient_data[OutputAffine.la_affine.value] = la_affine\n",
        "        \n",
        "        return patient_data\n",
        "    \n",
        "    @staticmethod\n",
        "    def to_structure(patient_data: Dict[str, sitk.Image], has_affine_matrix: bool,\n",
        "                     has_gt: bool = True):\n",
        "        output_data = []\n",
        "        if has_gt:\n",
        "            output_data.append(({'input_sa': patient_data[FileType.sa_ed.value],\n",
        "                                 'input_la': patient_data[FileType.la_ed.value]},\n",
        "                                {'output_sa': patient_data[FileType.sa_ed_gt.value],\n",
        "                                 'output_la': patient_data[FileType.la_ed_gt.value]}))\n",
        "            \n",
        "            output_data.append(({'input_sa': patient_data[FileType.sa_es.value],\n",
        "                                 'input_la': patient_data[FileType.la_es.value]},\n",
        "                                {'output_sa': patient_data[FileType.sa_es_gt.value],\n",
        "                                 'output_la': patient_data[FileType.la_es_gt.value]}))\n",
        "        else:\n",
        "            output_data.append(({'input_sa': patient_data[FileType.sa_ed.value],\n",
        "                                 'input_la': patient_data[FileType.la_ed.value]},))\n",
        "            \n",
        "            output_data.append(({'input_sa': patient_data[FileType.sa_es.value],\n",
        "                                 'input_la': patient_data[FileType.la_es.value]},))\n",
        "            \n",
        "        if has_affine_matrix:\n",
        "            for data in output_data:\n",
        "                data[0]['input_sa_affine'] = patient_data[OutputAffine.sa_affine.value]\n",
        "                data[0]['input_la_affine'] = patient_data[OutputAffine.la_affine.value]\n",
        "                \n",
        "        return output_data\n",
        "        \n",
        "\n",
        "    def generator(self, patient_directory: Union[str, Path], affine_matrix: bool,\n",
        "                  has_gt: bool = True) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        if self.is_cached(patient_directory, has_gt):\n",
        "            patient_data = self.load_cache(patient_directory, has_gt)\n",
        "        else:\n",
        "            patient_data = DataGenerator.load_patient_data(patient_directory, has_gt)\n",
        "            patient_data = DataGenerator.preprocess_patient_data(patient_data,\n",
        "                                                                 self.target_spacing,\n",
        "                                                                 self.target_size,\n",
        "                                                                 has_gt,\n",
        "                                                                 affine_matrix)\n",
        "            self.save_cache(patient_directory, patient_data)\n",
        "\n",
        "        \n",
        "        patient_data = self.to_numpy(patient_data)\n",
        "    \n",
        "        output_data = self.to_structure(patient_data, affine_matrix, has_gt)\n",
        "        return output_data\n",
        "\n",
        "    \n",
        "    def sitk_generator(self, patient_directory: Union[str, Path], has_gt: bool = True) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        \"\"\"\n",
        "        Returns pre- and post-processed data in sitk\n",
        "        \"\"\"\n",
        "        if self.is_cached(patient_directory, has_gt):\n",
        "            pre_patient_data = DataGenerator.load_patient_data(patient_directory, has_gt)\n",
        "            post_patient_data = self.load_cache(patient_directory, has_gt)\n",
        "        else:\n",
        "            pre_patient_data = DataGenerator.load_patient_data(patient_directory, has_gt)\n",
        "            post_patient_data = DataGenerator.load_patient_data(patient_directory, has_gt)\n",
        "            post_patient_data = DataGenerator.preprocess_patient_data(post_patient_data,\n",
        "                                                                      self.target_spacing,\n",
        "                                                                      self.target_size,\n",
        "                                                                      has_gt,\n",
        "                                                                      False)\n",
        "            self.save_cache(patient_directory, pre_patient_data)\n",
        "            \n",
        "        \n",
        "        pre_output_data = self.to_structure(pre_patient_data, False, has_gt)\n",
        "        post_output_data = self.to_structure(post_patient_data, False, has_gt)\n",
        "        \n",
        "        return pre_output_data, post_output_data\n",
        "        \n",
        "        \n",
        "    def train_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.train_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=False)\n",
        "            \n",
        "            yield patient_data[0]   # End diastolic\n",
        "            yield patient_data[1]   # End systolic\n",
        "        \n",
        "    \n",
        "    def validation_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.validation_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=False)\n",
        "            \n",
        "            yield patient_data[0]\n",
        "            yield patient_data[1]\n",
        "            \n",
        "    \n",
        "    def test_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.test_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=False)\n",
        "            \n",
        "            yield patient_data[0]\n",
        "            yield patient_data[1]\n",
        "            \n",
        "    \n",
        "    def test_generator_inference(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.test_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=False, has_gt=False)\n",
        "            pre_patient_data, post_patient_data = self.sitk_generator(patient_directory, has_gt=False)\n",
        "            \n",
        "            yield patient_data[0], pre_patient_data[0], post_patient_data[0], patient_directory, 'ed'\n",
        "            yield patient_data[1], pre_patient_data[1], post_patient_data[1], patient_directory, 'es'\n",
        "        \n",
        "        \n",
        "    def train_affine_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.train_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=True)\n",
        "            \n",
        "            yield patient_data[0]   # End diastolic\n",
        "            yield patient_data[1]   # End systolic\n",
        "        \n",
        "    \n",
        "    def validation_affine_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.validation_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=True)\n",
        "            \n",
        "            yield patient_data[0]\n",
        "            yield patient_data[1]\n",
        "            \n",
        "    \n",
        "    def test_affine_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.test_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=True)\n",
        "            \n",
        "            yield patient_data[0]\n",
        "            yield patient_data[1]\n",
        "\n",
        "\n",
        "    def test_affine_generator_inference(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.test_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=True, has_gt=False)\n",
        "            pre_patient_data, post_patient_data = self.sitk_generator(patient_directory, has_gt=False)\n",
        "            \n",
        "            yield patient_data[0], pre_patient_data[0], post_patient_data[0], patient_directory, 'ed'\n",
        "            yield patient_data[1], pre_patient_data[1], post_patient_data[1], patient_directory, 'es'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv7FQFqgj1z1"
      },
      "source": [
        "src/data/tf_generator.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA5s4YjBj5ml"
      },
      "source": [
        "from typing import Dict, Tuple, Union\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class TensorFlowDataGenerator():\n",
        "    \n",
        "    @staticmethod\n",
        "    def _prepare_generators(dg: DataGenerator, use_affine: bool, batch_size: int,\n",
        "                            output_shapes: Tuple[Dict[str, tf.TensorShape]],\n",
        "                            output_types: Tuple[Dict[str, tf.dtypes.DType]],\n",
        "                            max_buffer_size: Union[int, None]=None,\n",
        "                            floating_precision: str='32') -> Tuple[tf.data.Dataset]:\n",
        "        \n",
        "        buffer_size = len(dg.train_list) * 2\n",
        "        if max_buffer_size is not None:\n",
        "            buffer_size = min(buffer_size, max_buffer_size)    \n",
        "\n",
        "        generator_type = dg.train_affine_generator if use_affine else dg.train_generator\n",
        "        train_generator = tf.data.Dataset.from_generator(generator_type,\n",
        "                                                         output_types=output_types,\n",
        "                                                         output_shapes=output_shapes)\n",
        "        train_generator = train_generator.shuffle(buffer_size=buffer_size,\n",
        "                                                  seed=4875,\n",
        "                                                  reshuffle_each_iteration=True\n",
        "                                                  ).batch(batch_size).prefetch(2)\n",
        "        \n",
        "        generator_type = dg.validation_affine_generator if use_affine else dg.validation_generator\n",
        "        validation_generator = tf.data.Dataset.from_generator(generator_type,\n",
        "                                                              output_types=output_types,\n",
        "                                                              output_shapes=output_shapes)\n",
        "        validation_generator = validation_generator.batch(batch_size)\n",
        "        \n",
        "        inference = False\n",
        "        if inference:\n",
        "            generator_type = dg.test_affine_generator_inference if use_affine else dg.test_generator_inference\n",
        "        else:\n",
        "            generator_type = dg.test_affine_generator if use_affine else dg.test_generator\n",
        "        test_generator = tf.data.Dataset.from_generator(generator_type,\n",
        "                                                        output_types=output_types)\n",
        "        test_generator = test_generator.batch(batch_size)\n",
        "        \n",
        "        return train_generator, validation_generator, test_generator, dg\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def get_generators(batch_size: int, max_buffer_size: Union[int, None]=None,\n",
        "                       floating_precision: str='32') -> Tuple[tf.data.Dataset]:\n",
        "        dg = DataGenerator(floating_precision)\n",
        "        \n",
        "        output_shapes = ({'input_sa': tf.TensorShape(dg.sa_shape),\n",
        "                          'input_la': tf.TensorShape(dg.la_shape)},\n",
        "                         {'output_sa': tf.TensorShape(dg.sa_target_shape),\n",
        "                          'output_la': tf.TensorShape(dg.la_target_shape)})\n",
        "        \n",
        "        if floating_precision == '16':\n",
        "            float_type = tf.float16\n",
        "        else:\n",
        "            float_type = tf.float32\n",
        "        # TODO: Change to dynamic input parameters\n",
        "        output_types = ({'input_sa': float_type,\n",
        "                         'input_la': float_type},\n",
        "                        {'output_sa': float_type,\n",
        "                         'output_la': float_type})\n",
        "\n",
        "        use_affine = False\n",
        "        return TensorFlowDataGenerator._prepare_generators(dg, use_affine, batch_size,\n",
        "                                                           output_shapes,\n",
        "                                                           output_types,\n",
        "                                                           max_buffer_size,\n",
        "                                                           floating_precision)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_affine_generators(batch_size: int, max_buffer_size: Union[int, None]=None,\n",
        "                              floating_precision: str='32') -> Tuple[tf.data.Dataset]:\n",
        "        dg = DataGenerator(floating_precision)\n",
        "        \n",
        "        output_shapes = ({'input_sa': tf.TensorShape(dg.sa_shape),\n",
        "                          'input_la': tf.TensorShape(dg.la_shape),\n",
        "                          'input_sa_affine': tf.TensorShape(dg.affine_shape),\n",
        "                          'input_la_affine': tf.TensorShape(dg.affine_shape)},\n",
        "                         {'output_sa': tf.TensorShape(dg.sa_target_shape),\n",
        "                          'output_la': tf.TensorShape(dg.la_target_shape)})\n",
        "        \n",
        "        if floating_precision == '16':\n",
        "            float_type = tf.float16\n",
        "        else:\n",
        "            float_type = tf.float32\n",
        "        # TODO: Change to dynamic input parameters\n",
        "        output_types = ({'input_sa': float_type,\n",
        "                         'input_la': float_type,\n",
        "                         'input_sa_affine': tf.float32,\n",
        "                         'input_la_affine': tf.float32},\n",
        "                        {'output_sa': float_type,\n",
        "                         'output_la': float_type})\n",
        "\n",
        "        use_affine = True\n",
        "        return TensorFlowDataGenerator._prepare_generators(dg, use_affine, batch_size,\n",
        "                                                           output_shapes,\n",
        "                                                           output_types,\n",
        "                                                           max_buffer_size,\n",
        "                                                           floating_precision)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coSsv-QwlDMO"
      },
      "source": [
        "src/tf/loasses.loss.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK35_MWllGgE"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Loss taken from here:\n",
        "#    https://github.com/tensorflow/models/blob/master/official/vision/keras_cv/losses/focal_loss.py\n",
        "class FocalLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"Implements a Focal loss for classification problems.\n",
        "    Reference:\n",
        "      [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 alpha,\n",
        "                 gamma,\n",
        "                 reduction=tf.keras.losses.Reduction.AUTO,\n",
        "                 name=None):\n",
        "        \"\"\"Initializes `FocalLoss`.\n",
        "        Args:\n",
        "          alpha: The `alpha` weight factor for binary class imbalance.\n",
        "          gamma: The `gamma` focusing parameter to re-weight loss.\n",
        "          reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to\n",
        "            loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n",
        "            option will be determined by the usage context. For almost all cases\n",
        "            this defaults to `SUM_OVER_BATCH_SIZE`. When used with\n",
        "            `tf.distribute.Strategy`, outside of built-in training loops such as\n",
        "            `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE`\n",
        "            will raise an error. Please see this custom training [tutorial](\n",
        "              https://www.tensorflow.org/tutorials/distribute/custom_training) for\n",
        "                more details.\n",
        "          name: Optional name for the op. Defaults to 'retinanet_class_loss'.\n",
        "        \"\"\"\n",
        "        self._alpha = alpha\n",
        "        self._gamma = gamma\n",
        "        super(FocalLoss, self).__init__(reduction=reduction, name=name)\n",
        "    \n",
        "    \n",
        "    def call(self, y_true, y_pred):\n",
        "        \"\"\"Invokes the `FocalLoss`.\n",
        "        Args:\n",
        "          y_true: A tensor of size [batch, num_anchors, num_classes]\n",
        "          y_pred: A tensor of size [batch, num_anchors, num_classes]\n",
        "        Returns:\n",
        "          Summed loss float `Tensor`.\n",
        "        \"\"\"\n",
        "        with tf.name_scope('focal_loss'):\n",
        "            y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "            y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "            positive_label_mask = tf.equal(y_true, 1.0)\n",
        "            cross_entropy = (\n",
        "                tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
        "            probs = tf.sigmoid(y_pred)\n",
        "            probs_gt = tf.where(positive_label_mask, probs, 1.0 - probs)\n",
        "            # With small gamma, the implementation could produce NaN during back prop.\n",
        "            modulator = tf.pow(1.0 - probs_gt, self._gamma)\n",
        "            loss = modulator * cross_entropy\n",
        "            weighted_loss = tf.where(positive_label_mask, self._alpha * loss,\n",
        "                                     (1.0 - self._alpha) * loss)\n",
        "        \n",
        "        return weighted_loss\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'alpha': self._alpha,\n",
        "            'gamma': self._gamma,\n",
        "        }\n",
        "        base_config = super(FocalLoss, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "\n",
        "class TverskyLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"Implements a Tversky loss for classification problems.\n",
        "    Reference:\n",
        "      [Tversky loss function for image segmentation using 3D fully convolutional\n",
        "       deep networks](https://arxiv.org/abs/1706.05721).\n",
        "      \n",
        "      'In the case of α=β=0.5 the Tversky index simplifies to be the same as\n",
        "       the Dice coefficient, which is also equal to the F1 score. With α=β=1,\n",
        "       Equation 2 produces Tanimoto coefficient, and setting α+β=1 produces\n",
        "       the set of Fβ scores. Larger βs weigh recall higher than precision (by\n",
        "       placing more emphasis on false negatives)'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 alpha,\n",
        "                 beta,\n",
        "                 reduction=tf.keras.losses.Reduction.AUTO,\n",
        "                 name=None):\n",
        "        \"\"\"Initializes `TverskyLoss`.\n",
        "        Args:\n",
        "          alpha: The `alpha` weight factor for binary class imbalance.\n",
        "          gamma: The `gamma` focusing parameter to re-weight loss.\n",
        "          reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to\n",
        "            loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n",
        "            option will be determined by the usage context. For almost all cases\n",
        "            this defaults to `SUM_OVER_BATCH_SIZE`. When used with\n",
        "            `tf.distribute.Strategy`, outside of built-in training loops such as\n",
        "            `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE`\n",
        "            will raise an error. Please see this custom training [tutorial](\n",
        "              https://www.tensorflow.org/tutorials/distribute/custom_training) for\n",
        "                more details.\n",
        "          name: Optional name for the op.\n",
        "        \"\"\"\n",
        "        self._alpha = alpha\n",
        "        self._beta = beta\n",
        "        super(TverskyLoss, self).__init__(reduction=reduction, name=name)\n",
        "  \n",
        "  \n",
        "    def call(self, y_true, y_pred):\n",
        "        \"\"\"Invokes the `TverskyLoss`.\n",
        "        Args:\n",
        "          y_true: A tensor of size [batch, ..., num_classes]\n",
        "          y_pred: A tensor of size [batch, ..., num_classes]\n",
        "        Returns:\n",
        "          Summed loss float `Tensor`.\n",
        "        \"\"\"\n",
        "        with tf.name_scope('tversky_loss'):\n",
        "            epsilon = 1e-6\n",
        "            y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "            y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "            \n",
        "            # TODO: softmax is unstable\n",
        "            y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
        "            \n",
        "            dim = tf.reduce_prod(tf.shape(y_true)[1:])\n",
        "            y_true_flatten = tf.reshape(y_true, [-1, dim])\n",
        "            y_pred_flatten = tf.reshape(y_pred, [-1, dim])\n",
        "            \n",
        "            tp = tf.math.reduce_sum(y_true_flatten * y_pred_flatten, axis=-1)\n",
        "            fp = tf.math.reduce_sum((1.0 - y_true_flatten) * y_pred_flatten, axis=-1)\n",
        "            fn = tf.math.reduce_sum(y_true_flatten * (1.0 - y_pred_flatten), axis=-1)\n",
        "            \n",
        "            tversky = (tp + epsilon) / (tp + self._alpha * fp + self._beta * fn + epsilon)\n",
        "            \n",
        "            loss = 1 - tf.reduce_mean(tversky)\n",
        "    \n",
        "        return loss\n",
        "  \n",
        "  \n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'alpha': self._alpha,\n",
        "            'beta': self._beta\n",
        "        }\n",
        "        base_config = super(TverskyLoss, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rbTKwB8lNP9"
      },
      "source": [
        "src/tf/metrics/metrics.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FsgC_DNlWHU"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "@tf.autograph.experimental.do_not_convert\n",
        "def dice(y_true, y_pred):\n",
        "    epsilon = 1e-6\n",
        "    \n",
        "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "    # Expected y_pred to be 'logits'\n",
        "    y_pred = tf.nn.softmax(y_pred)\n",
        "    \n",
        "    dim = tf.reduce_prod(tf.shape(y_true)[1:])\n",
        "    y_true_flatten = tf.reshape(y_true, [-1, dim])\n",
        "    y_pred_flatten = tf.reshape(y_pred, [-1, dim])\n",
        "\n",
        "    intersection = tf.math.reduce_sum(y_true_flatten * y_pred_flatten, axis=-1)\n",
        "    \n",
        "    union = tf.math.reduce_sum(y_true_flatten, axis=-1) + \\\n",
        "        tf.math.reduce_sum(y_pred_flatten, axis=-1)\n",
        "    \n",
        "    dice_coef = tf.math.reduce_mean((2. * intersection + epsilon) / (union + epsilon))\n",
        "\n",
        "    return dice_coef\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OwEpFVglYPk"
      },
      "source": [
        "src/tf/layers/transformer.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBaygLfJlevM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "from voxelmorph.tf.layers import SpatialTransformer\n",
        "\n",
        "\n",
        "class TargetAffineLayer(Layer):\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super(self.__class__, self).__init__(**kwargs)\n",
        "    \n",
        "    \n",
        "    @tf.autograph.experimental.do_not_convert\n",
        "    def _get_transformation(self, inputs):\n",
        "        image_affine = inputs[0]\n",
        "        target_affine = inputs[1]\n",
        "        \n",
        "        affine_transform = tf.cond(tf.reduce_all(tf.math.equal(target_affine, image_affine)),\n",
        "                                   lambda: tf.eye(4, dtype=image_affine.dtype),\n",
        "                                   lambda: tf.tensordot(tf.linalg.inv(image_affine),\n",
        "                                                        target_affine, axes=1))\n",
        "        \n",
        "        return affine_transform\n",
        "        \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "    \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "            inputs: list with four entries\n",
        "        \"\"\"\n",
        "        # check shapes\n",
        "        assert len(inputs) == 2, \"inputs has to be len 2, found: %d\" % len(inputs)\n",
        "        image_affine = tf.cast(inputs[0], dtype=tf.float32)\n",
        "        target_affine = tf.cast(inputs[1], dtype=tf.float32)\n",
        "        \n",
        "        affine_transform = tf.map_fn(self._get_transformation,\n",
        "                                     [image_affine, target_affine],\n",
        "                                     dtype=tf.float32)\n",
        "        \n",
        "        return affine_transform\n",
        "    \n",
        "\n",
        "\n",
        "class TargetShapePad(Layer):\n",
        "    \n",
        "    def __init__(self, image_shape, target_shape, **kwargs):\n",
        "        super(self.__class__, self).__init__(**kwargs)\n",
        "        \n",
        "        # TODO\n",
        "        #zero = tf.constant(0, dtype=tf.int32)\n",
        "        #self.paddings = [(zero, tf.math.maximum(tf.cast(target_shape[0] - image_shape[0], tf.int32), zero)),\n",
        "        #                 (zero, tf.math.maximum(tf.cast(target_shape[1] - image_shape[1], tf.int32), zero)),\n",
        "        #                 (zero, zero)]\n",
        "        self.paddings = [(0, 0),\n",
        "                         (0, 0),\n",
        "                         (0, 0)]\n",
        "        \n",
        "        self.init_config = {'image_shape': image_shape, 'target_shape': target_shape, **kwargs}\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        return self.init_config\n",
        "    \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        padded_image = tf.keras.layers.ZeroPadding3D(self.paddings)(inputs)\n",
        "\n",
        "        return padded_image\n",
        "\n",
        "\n",
        "\n",
        "class TargetShapeCrop(Layer):\n",
        "    \n",
        "    def __init__(self, image_shape, target_shape, **kwargs):\n",
        "        super(self.__class__, self).__init__(**kwargs)\n",
        "        \n",
        "        # TODO\n",
        "        #zero = tf.constant(0, dtype=tf.int32)\n",
        "        #self.cropping = [(zero, tf.math.maximum(tf.cast(image_shape[0] - target_shape[0], tf.int32), zero)),\n",
        "        #                 (zero, tf.math.maximum(tf.cast(image_shape[1] - target_shape[1], tf.int32), zero)),\n",
        "        #                 (zero, tf.math.maximum(tf.cast(image_shape[2] - target_shape[2], tf.int32), zero))]\n",
        "        self.cropping = [(0, 0),\n",
        "                         (0, 0),\n",
        "                         (0, 16)]\n",
        "        \n",
        "        self.init_config = {'image_shape': image_shape, 'target_shape': target_shape, **kwargs}\n",
        "        \n",
        "    \n",
        "    def get_config(self):\n",
        "        return self.init_config\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        cropped_image = tf.keras.layers.Cropping3D(self.cropping)(inputs)\n",
        "        \n",
        "        return cropped_image\n",
        "    \n",
        "    \n",
        "def spatial_target_transformer(x, affine_matrix, target_affine_matrix,\n",
        "                               image_shape, target_image_shape):\n",
        "    affine = TargetAffineLayer()([affine_matrix, target_affine_matrix])\n",
        "    \n",
        "    x = TargetShapePad(image_shape, target_image_shape)(x)\n",
        "    \n",
        "    original_dtype = x.dtype\n",
        "    x = tf.cast(x, dtype=tf.float32)\n",
        "    x = SpatialTransformer(interp_method='linear',\n",
        "                           indexing='ij',\n",
        "                           add_identity=False,\n",
        "                           shift_center=False,\n",
        "                           fill_value=0.0,\n",
        "                           dtype=tf.float32)([x, affine])\n",
        "    x = tf.cast(x, dtype=original_dtype)\n",
        "    \n",
        "    x = TargetShapeCrop(image_shape, target_image_shape)(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lks12hw8lked"
      },
      "source": [
        "src/tf/models/test_model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd4qQBWBlqBV"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#from tf.layers.transformer import spatial_target_transformer\n",
        "\n",
        "\n",
        "\n",
        "def shared_2d_branch(input_shape, kernel_initializer):\n",
        "    shared_input = keras.layers.Input(shape=input_shape)\n",
        "    \n",
        "    x = layers.Conv2D(32, (9, 9), padding='same', activation='relu',\n",
        "                      kernel_initializer=kernel_initializer)(shared_input)\n",
        "    x = layers.Conv2D(64, (7, 7), padding='same', activation='relu',\n",
        "                      kernel_initializer=kernel_initializer)(x)\n",
        "    x = layers.Conv2D(128, (5, 5), padding='same', activation='relu',\n",
        "                      kernel_initializer=kernel_initializer)(x)\n",
        "    x = layers.Conv2D(17, (3, 3), padding='same', activation='relu',\n",
        "                      kernel_initializer=kernel_initializer)(x)\n",
        "    x = layers.DepthwiseConv2D((7, 7), padding='same', activation='relu',\n",
        "                               kernel_initializer=kernel_initializer)(x)\n",
        "    \n",
        "    shared_model = keras.models.Model(shared_input, x)\n",
        "    return shared_model\n",
        "\n",
        "\n",
        "def get_model(sa_input_shape, la_input_shape, num_classes) -> keras.Model:\n",
        "    # A basic model to test pipeline\n",
        "    \n",
        "    kernel_initializer = 'glorot_uniform'\n",
        "    \n",
        "    input_sa = keras.Input(shape=sa_input_shape, name='input_sa')\n",
        "    input_la = keras.Input(shape=la_input_shape, name='input_la')\n",
        "    \n",
        "    x_sa = input_sa\n",
        "    x_la = input_la\n",
        "    \n",
        "    # Transform the long-axis image to have the same number of channels as the\n",
        "    # short-axis (so they can be passed to the shared branch)\n",
        "    x_la = layers.Conv2D(sa_input_shape[-1], (3, 3), padding='same',\n",
        "                         kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    shared_layers = shared_2d_branch(sa_input_shape, kernel_initializer)\n",
        "    x_sa = shared_layers(x_sa)\n",
        "    \n",
        "    # Now predict each one independantly\n",
        "    # Short-Axis branch\n",
        "    # Reshape the image so that it is treated as a 3D image (W, H, D) to (W, H, D, C)\n",
        "    x_sa = tf.expand_dims(x_sa, axis=-1)\n",
        "    \n",
        "    x_sa = layers.Conv3D(16, (5, 5, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    x_sa = layers.Conv3D(32, (3, 3, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    x_sa = layers.Conv3D(64, (3, 3, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    output_sa = layers.Conv3D(num_classes, (1, 1, 1), padding='same',\n",
        "                              kernel_initializer=kernel_initializer, name='output_sa')(x_sa)\n",
        "    \n",
        "    x_la = shared_layers(x_la)\n",
        "    \n",
        "    # Long-Axis branch\n",
        "    x_la = layers.Conv2D(32, (5, 5), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    x_la = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    x_la = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    output_la = layers.Conv2D(num_classes, (1, 1), padding='same',\n",
        "                              kernel_initializer=kernel_initializer, name='output_la')(x_la)\n",
        "    \n",
        "    \n",
        "    model = keras.Model([input_sa, input_la], [output_sa, output_la])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "\n",
        "def get_affine_model(sa_input_shape, la_input_shape, num_classes) -> keras.Model:\n",
        "    # A basic model to test pipeline and including affine matrices/spatial transformer\n",
        "    \n",
        "    kernel_initializer = 'glorot_uniform'\n",
        "    \n",
        "    input_sa = keras.Input(shape=sa_input_shape, name='input_sa')\n",
        "    input_la = keras.Input(shape=la_input_shape, name='input_la')\n",
        "    \n",
        "    input_sa_affine = keras.Input(shape=(4, 4), name='input_sa_affine', dtype=tf.float32)\n",
        "    input_la_affine = keras.Input(shape=(4, 4), name='input_la_affine', dtype=tf.float32)\n",
        "    \n",
        "    x_sa = input_sa\n",
        "    x_la = input_la\n",
        "    \n",
        "    # Transform the long-axis image to have the same number of channels as the\n",
        "    # short-axis (so they can be passed to the shared branch)\n",
        "    x_la = layers.Conv2D(sa_input_shape[-1], (3, 3), padding='same',\n",
        "                         kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    #shared_layers = shared_2d_branch(sa_input_shape, kernel_initializer)\n",
        "    shared_layers = layers.Conv2D(17, (9, 9), padding='same', activation='relu',\n",
        "                      kernel_initializer=kernel_initializer)\n",
        "    x_sa = shared_layers(x_sa)\n",
        "    \n",
        "    # Now predict each one independantly\n",
        "    # Short-Axis branch\n",
        "    # Reshape the image so that it is treated as a 3D image (W, H, D) to (W, H, D, C)\n",
        "    x_sa = tf.expand_dims(x_sa, axis=-1)\n",
        "    \n",
        "    x_sa = layers.Conv3D(16, (5, 5, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    x_sa = layers.Conv3D(32, (3, 3, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    x_sa = layers.Conv3D(64, (3, 3, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    output_sa = layers.Conv3D(num_classes, (1, 1, 1), padding='same',\n",
        "                              kernel_initializer=kernel_initializer, name='output_sa')(x_sa)\n",
        "    \n",
        "    x_la = shared_layers(x_la)\n",
        "    # Long-Axis branch\n",
        "    \n",
        "    x_la = layers.Conv2D(32, (5, 5), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    x_la = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    x_la = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "      \n",
        "    x_la = layers.Conv2D(num_classes, (1, 1), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    \n",
        "    # output_sa or x_sa as input to spatial transformer\n",
        "    x_la_t = spatial_target_transformer(output_sa, input_sa_affine, input_la_affine,\n",
        "                                        sa_input_shape, la_input_shape)\n",
        "    \n",
        "    # Reshape from 3d to 2d (depth size is expected to be 1 after the spatial transformer)\n",
        "    x_la_t = layers.Reshape((la_input_shape[0], la_input_shape[1], -1))(x_la_t)\n",
        "    \n",
        "    x_la = layers.Concatenate()([x_la, x_la_t])\n",
        "    \n",
        "    output_la = layers.Conv2D(num_classes, (1, 1), padding='same',\n",
        "                              kernel_initializer=kernel_initializer, name='output_la')(x_la)\n",
        "    \n",
        "    model = keras.Model([input_sa, input_la, input_sa_affine, input_la_affine],\n",
        "                        [output_sa, output_la])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um3DD7qRl5E4"
      },
      "source": [
        "src/configuration.py\\\n",
        "Use to select hyperparmaeter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr5lvs5Tl-_D"
      },
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "# Sortable version of HParam\n",
        "class HParamS(hp.HParam):\n",
        "    \n",
        "    def __init__(self, name, domain=None, display_name=None, description=None):\n",
        "        hp.HParam.__init__(self, name, domain, display_name, description)\n",
        "        \n",
        "    def __lt__(self, other):\n",
        "        return self.name.lower() < other.name.lower()\n",
        "\n",
        "\n",
        "class HyperParameters():\n",
        "    \n",
        "    def __init__(self, search_type: str):\n",
        "        # TODO: Load from file rather than hard-coded in this file\n",
        "        self.HP_FLOATING_POINT = HParamS('floating_point', hp.Discrete(['16']))\n",
        "        self.HP_EPOCHS = HParamS('epochs', hp.Discrete([100]))\n",
        "        self.HP_BATCH_SIZE = HParamS('batch_size', hp.Discrete([4]))\n",
        "        self.HP_LEANRING_RATE = HParamS('learning_rate', hp.Discrete([0.0005]))\n",
        "        self.HP_OPTIMISER = HParamS('optimiser', hp.Discrete(['adam']))\n",
        "        self.HP_LOSS = HParamS('loss', hp.Discrete(['focal']))\n",
        "        self.HP_DROPOUT = HParamS('drop_out', hp.Discrete([0.0]))\n",
        "        \n",
        "        self.parameter_dict = {}\n",
        "        self.parameter_dict[self.HP_FLOATING_POINT] = self.HP_FLOATING_POINT.domain.values\n",
        "        self.parameter_dict[self.HP_EPOCHS] = self.HP_EPOCHS.domain.values\n",
        "        self.parameter_dict[self.HP_BATCH_SIZE] = self.HP_BATCH_SIZE.domain.values\n",
        "        self.parameter_dict[self.HP_LEANRING_RATE] = self.HP_LEANRING_RATE.domain.values\n",
        "        self.parameter_dict[self.HP_OPTIMISER] = self.HP_OPTIMISER.domain.values\n",
        "        self.parameter_dict[self.HP_LOSS] = self.HP_LOSS.domain.values\n",
        "        self.parameter_dict[self.HP_DROPOUT] = self.HP_DROPOUT.domain.values\n",
        "        \n",
        "        if search_type == 'grid':\n",
        "            self.parameter_space = ParameterGrid(self.parameter_dict)\n",
        "        else:\n",
        "            raise ValueError('Invalid \\'search_type\\' input. Given: {}'.format(search_type))\n",
        "        \n",
        "        \n",
        "    def __iter__(self):\n",
        "        parameter_list = list(self.parameter_space)\n",
        "        for parameter in parameter_list:\n",
        "            yield parameter\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "if __name__ == '__main__':\n",
        "    config = HyperParameters(search_type='grid')\n",
        "    for i in config:\n",
        "        print(i)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ0BK0h-l0J8"
      },
      "source": [
        "src/run_training.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJa-PobZ2E4P"
      },
      "source": [
        "baes_output_path = '/content/gdrive/MyDrive/mnms2_challenge/'   # Example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGxbkmNVlztv"
      },
      "source": [
        "import os\n",
        "\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "#from configuration import HyperParameters\n",
        "#from data import TensorFlowDataGenerator\n",
        "#from tf.models import test_model\n",
        "#from tf.losses.loss import FocalLoss, TverskyLoss\n",
        "#from tf.metrics.metrics import dice\n",
        "\n",
        "\n",
        "__SEED = 1456\n",
        "os.environ['PYTHONHASHSEED'] = str(__SEED)\n",
        "random.seed(__SEED)\n",
        "tf.random.set_seed(__SEED)\n",
        "np.random.seed(__SEED)\n",
        "\n",
        "\n",
        "def get_callbacks(prefix: str, checkpoint_directory: str, hparams):\n",
        "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_directory,\n",
        "        save_weights_only=False,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True)\n",
        "    \n",
        "    log_dir = os.path.join(baes_output_path, 'logs', 'fit', prefix + datetime.datetime.now().strftime('_%Y%m%d-%H%M%S')) + '/'\n",
        "    #file_writer = tf.summary.create_file_writer(log_dir + '\\\\metrics')\n",
        "    #file_writer.set_as_default()\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    hparams_callback = hp.KerasCallback(log_dir, hparams)\n",
        "    \n",
        "    return [model_checkpoint_callback,\n",
        "            tensorboard_callback,\n",
        "            hparams_callback]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    hyper_parameters = HyperParameters('grid')\n",
        "    \n",
        "    for hparams in hyper_parameters:\n",
        "        keras.backend.clear_session()\n",
        "        \n",
        "        fp = hparams[hyper_parameters.HP_FLOATING_POINT]\n",
        "        if fp == '16':\n",
        "            policy = keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "            keras.mixed_precision.experimental.set_policy(policy)\n",
        "    \n",
        "        batch_size = hparams[hyper_parameters.HP_BATCH_SIZE]\n",
        "        (train_gen, validation_gen,\n",
        "         test_gen, data_gen) = TensorFlowDataGenerator.get_affine_generators(batch_size,\n",
        "                                                                             max_buffer_size=None,\n",
        "                                                                             floating_precision=fp)\n",
        "                                                                    \n",
        "        model = get_affine_model(data_gen.sa_shape, data_gen.la_shape, data_gen.n_classes)\n",
        "        \n",
        "        \n",
        "        learning_rate = hparams[hyper_parameters.HP_LEANRING_RATE]\n",
        "        if hparams[hyper_parameters.HP_OPTIMISER] == 'adam':\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "            \n",
        "        if hparams[hyper_parameters.HP_LOSS] == 'focal':\n",
        "            loss = FocalLoss(0.25, 2.0)\n",
        "        elif hparams[hyper_parameters.HP_LOSS] == 'tversky':\n",
        "            loss = TverskyLoss(0.5, 0.5)\n",
        "        elif hparams[hyper_parameters.HP_LOSS] == 'crossentropy':\n",
        "            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "            \n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=loss,\n",
        "            metrics=[dice])\n",
        "        \n",
        "        epochs = hparams[hyper_parameters.HP_EPOCHS]\n",
        "        prefix = 'test_model'\n",
        "        checkpoint_path = os.path.join(baes_output_path, 'checkpoint', prefix + datetime.datetime.now().strftime('_%Y%m%d-%H%M%S')) + '/'\n",
        "        model.fit(x=train_gen,\n",
        "                  validation_data=validation_gen,\n",
        "                  epochs=epochs,\n",
        "                  callbacks=get_callbacks(prefix, checkpoint_path, hparams),\n",
        "                  verbose=1)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}