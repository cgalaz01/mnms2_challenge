{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnms2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR3CyUbArjx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e98027-4b52-4f51-8e8b-4c7c22a23c42"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-bb40b437-d0ff-011a-d28b-3bcedc215c47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1-La81J4qoO",
        "outputId": "a5ab8133-7c47-49c4-9f5e-a850757c3d0b"
      },
      "source": [
        "# https://github.com/tensorflow/tensorflow/issues/46589\n",
        "!sudo apt-get install --no-install-recommends --allow-change-held-packages cuda-11-0 libcudnn8=8.0.5.39-1+cuda11.0 libcudnn8-dev=8.0.5.39-1+cuda11.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda-11-0 is already the newest version (11.0.3-1).\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8 libcudnn8-dev\n",
            "2 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 627 MB of archives.\n",
            "After this operation, 258 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8-dev 8.0.5.39-1+cuda11.0 [272 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.0.5.39-1+cuda11.0 [356 MB]\n",
            "Fetched 627 MB in 24s (26.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8-dev_8.0.5.39-1+cuda11.0_amd64.deb ...\n",
            "Unpacking libcudnn8-dev (8.0.5.39-1+cuda11.0) over (8.0.4.30-1+cuda11.0) ...\n",
            "Preparing to unpack .../libcudnn8_8.0.5.39-1+cuda11.0_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.0.5.39-1+cuda11.0) over (8.0.4.30-1+cuda11.0) ...\n",
            "Setting up libcudnn8 (8.0.5.39-1+cuda11.0) ...\n",
            "Setting up libcudnn8-dev (8.0.5.39-1+cuda11.0) ...\n",
            "update-alternatives: warning: forcing reinstallation of alternative /usr/include/x86_64-linux-gnu/cudnn_v7.h because link group libcudnn is broken\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in manual mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF8ADJu33qJG",
        "outputId": "af20288e-68fe-46ab-8b07-71d9f8927959"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNYn7f2Uj_hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a117938-09ad-4ca0-b116-2c5c884c2c3c"
      },
      "source": [
        "!pip install SimpleITK\n",
        "!pip install voxelmorph\n",
        "#!pip install tensorflow==2.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 54kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.0.2\n",
            "Collecting voxelmorph\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/77/fdcf9ff2c8450d447ba760122b50575cfc037921b5870dac61c04a4609cc/voxelmorph-0.1-py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.6MB/s \n",
            "\u001b[?25hCollecting neurite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/4b/705ff365b11bef90b73f5f680c66e34eb3053a7e9ab2bb0705be7b854f08/neurite-0.1-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (1.4.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (3.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (0.16.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (4.41.1)\n",
            "Collecting pystrum\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/3a/99e310f01f9e3ef4ab78d9e194c3b22bc53574c70c61c9c9bfc136161439/pystrum-0.1-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (7.1.2)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->voxelmorph) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->neurite->voxelmorph) (1.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (2.4.7)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->voxelmorph) (4.4.2)\n",
            "Installing collected packages: pystrum, neurite, voxelmorph\n",
            "Successfully installed neurite-0.1 pystrum-0.1 voxelmorph-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avY2iXtLo2LU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa13a957-11a7-42ee-cad3-c76d4e8fa209"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v144Jhl6nrCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d3d9d9-ce33-49a8-edce-f0de9f87689c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQuyQsYoJcL"
      },
      "source": [
        "# Change to the location of the preprocessed data (data_cache)\n",
        "data_zip_path = '/content/gdrive/MyDrive/mnms2_challenge/data_cache.zip'    # Example "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDYBLbSVzUQY"
      },
      "source": [
        "Copy data from google drive to Colab session (slightly slow process)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_RthMEAzX21"
      },
      "source": [
        "!cp \"{data_zip_path}\" .\n",
        "!unzip -q data_cache.zip\n",
        "!rm data_cache.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT7nJbC_0q63"
      },
      "source": [
        "# session path\n",
        "path_to_data_cache = '/content/data_cache/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQEHJBWjnXO"
      },
      "source": [
        "src/data/preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nV-OcItjukm"
      },
      "source": [
        "from typing import List, Union, Tuple\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "\n",
        "import SimpleITK as sitk\n",
        "\n",
        "\n",
        "class Preprocess():\n",
        "    \n",
        "    @staticmethod\n",
        "    def resample_image(image: sitk.Image, out_spacing: Tuple[float]=(1.0, 1.0, 1.0),\n",
        "                       out_size: Union[None, Tuple[int]]=None, is_label: bool=False,\n",
        "                       pad_value: float=0) -> sitk.Image:\n",
        "        original_spacing = np.array(image.GetSpacing())\n",
        "        original_size = np.array(image.GetSize())\n",
        "        \n",
        "        if original_size[-1] == 1:\n",
        "            out_spacing = list(out_spacing)\n",
        "            out_spacing[-1] = original_spacing[-1]\n",
        "            out_spacing = tuple(out_spacing)\n",
        "    \n",
        "        if out_size is None:\n",
        "            out_size = np.round(np.array(original_size * original_spacing / np.array(out_spacing))).astype(int)\n",
        "        else:\n",
        "            out_size = np.array(out_size)\n",
        "    \n",
        "        original_direction = np.array(image.GetDirection()).reshape(len(original_spacing),-1)\n",
        "        original_center = (np.array(original_size, dtype=float) - 1.0) / 2.0 * original_spacing\n",
        "        out_center = (np.array(out_size, dtype=float) - 1.0) / 2.0 * np.array(out_spacing)\n",
        "    \n",
        "        original_center = np.matmul(original_direction, original_center)\n",
        "        out_center = np.matmul(original_direction, out_center)\n",
        "        out_origin = np.array(image.GetOrigin()) + (original_center - out_center)\n",
        "    \n",
        "        resample = sitk.ResampleImageFilter()\n",
        "        resample.SetOutputSpacing(out_spacing)\n",
        "        resample.SetSize(out_size.tolist())\n",
        "        resample.SetOutputDirection(image.GetDirection())\n",
        "        resample.SetOutputOrigin(out_origin.tolist())\n",
        "        resample.SetTransform(sitk.Transform())\n",
        "        resample.SetDefaultPixelValue(pad_value)\n",
        "    \n",
        "        if is_label:\n",
        "            resample.SetInterpolator(sitk.sitkNearestNeighbor)\n",
        "        else:\n",
        "            resample.SetInterpolator(sitk.sitkBSpline)\n",
        "    \n",
        "        return resample.Execute(image)\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def normalise_intensities(image: sitk.Image) -> sitk.Image:\n",
        "        # Normalise image fro hypothetical 0-500 to 0-1 range\n",
        "        normalised_image = sitk.Cast(image, sitk.sitkFloat32) / 500.0\n",
        "        \n",
        "        return normalised_image\n",
        "    \n",
        "    \n",
        "\n",
        "class Registration():\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def _function_register(initial_transform, moving_image, fixed_image,\n",
        "                           learning_rate, histogram_bins, sampling_rate,\n",
        "                           seed) -> Tuple[sitk.Transform, float]:\n",
        "    \n",
        "        sitk.ProcessObject.SetGlobalDefaultNumberOfThreads(1)\n",
        "        registration_method = sitk.ImageRegistrationMethod()\n",
        "            \n",
        "        # Similarity metric settings.\n",
        "        registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=histogram_bins)\n",
        "        registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
        "        registration_method.SetMetricSamplingPercentage(sampling_rate, seed=seed)\n",
        "        \n",
        "        registration_method.SetInterpolator(sitk.sitkLinear)\n",
        "        \n",
        "        # Optimizer settings.\n",
        "        if learning_rate == None:\n",
        "            estimate_learning_rate = registration_method.EachIteration\n",
        "            learning_rate = 0\n",
        "        else:\n",
        "            estimate_learning_rate = registration_method.Never\n",
        "            \n",
        "        registration_method.SetOptimizerAsGradientDescent(learningRate=learning_rate,\n",
        "                                                          numberOfIterations=100,\n",
        "                                                          convergenceMinimumValue=1e-12,\n",
        "                                                          convergenceWindowSize=10,\n",
        "                                                          estimateLearningRate=estimate_learning_rate)\n",
        "    \n",
        "        registration_method.SetOptimizerScalesFromPhysicalShift()\n",
        "        \n",
        "        registration_method.SetInitialTransform(initial_transform, inPlace=True)        \n",
        "        \n",
        "        transform = registration_method.Execute(sitk.Cast(fixed_image, sitk.sitkFloat32), \n",
        "                                                sitk.Cast(moving_image, sitk.sitkFloat32))\n",
        "        \n",
        "        \n",
        "        return transform, registration_method.GetMetricValue()\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def _parallel_register(initial_transform, moving_image, fixed_image,\n",
        "                           learning_rate_list, histogram_bins, sampling_rate,\n",
        "                           seed) -> Tuple[sitk.Transform, float]:\n",
        "        \n",
        "        function_input = [(sitk.AffineTransform(initial_transform),\n",
        "                           moving_image,\n",
        "                           fixed_image,\n",
        "                           learning_rate_list[i],\n",
        "                           histogram_bins,\n",
        "                           sampling_rate,\n",
        "                           seed) for i in range(len(learning_rate_list))]\n",
        "        \n",
        "        with Pool() as pool:\n",
        "            output_results = pool.starmap(Registration._function_register, function_input)\n",
        "\n",
        "        selected_transform = None\n",
        "        min_metric_value = 1e5\n",
        "        for i in range(len(output_results)):\n",
        "            transform, metric_value = output_results[i]\n",
        "            if metric_value < min_metric_value:\n",
        "                min_metric_value = metric_value\n",
        "                selected_transform = transform\n",
        "                \n",
        "        return selected_transform, min_metric_value\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def _major_alignment(moving_image: sitk.Image, fixed_image: sitk.Image,\n",
        "                         debug_output: int=0) -> Tuple[sitk.Transform, float]:\n",
        "        debug_image_outputs = []\n",
        "        debug_image_moving = []\n",
        "        debug_image_fixed = []\n",
        "        \n",
        "        sitk.ProcessObject.SetGlobalDefaultNumberOfThreads(1)\n",
        "        \n",
        "        initial_transform = sitk.AffineTransform(3)\n",
        "        \n",
        "        if debug_output > 0:\n",
        "            debug_image = sitk.Resample(moving_image,\n",
        "                                        fixed_image,\n",
        "                                        initial_transform,\n",
        "                                        sitk.sitkLinear,\n",
        "                                        0.0,\n",
        "                                        moving_image.GetPixelID())\n",
        "            debug_image_moving.append(debug_image)\n",
        "            debug_image_fixed.append(fixed_image)\n",
        "        \n",
        "        \n",
        "        transform = initial_transform\n",
        "        \n",
        "        \n",
        "        gaussian_sigma = [8, 4, 2, 1, 0]\n",
        "        \n",
        "        histogram_bins = 200\n",
        "        learning_rate_list = [[8.0, 4.0, 2.0, 1.0, None],\n",
        "                              [4.0, 2.0, 1.0, 0.5, None],\n",
        "                              [2.0, 1.0, 0.5, 0.25, None],\n",
        "                              [1.0, 0.5, 0.25, 0.1, None],\n",
        "                              [0.5, 0.25, 0.1, 0.05, None]]\n",
        "        sampling_rate = 1.0\n",
        "        \n",
        "        seed = 12453\n",
        "        \n",
        "        for i in range(len(gaussian_sigma)):\n",
        "                \n",
        "            numpy_fixed_image = sitk.GetArrayFromImage(fixed_image)    \n",
        "            numpy_fixed_image = ndimage.gaussian_filter(numpy_fixed_image,\n",
        "                                                        sigma=(1,\n",
        "                                                               gaussian_sigma[i],\n",
        "                                                               gaussian_sigma[i]),\n",
        "                                                        mode='constant')\n",
        "            \n",
        "            \n",
        "            tmp_fixed_image = sitk.GetImageFromArray(numpy_fixed_image)\n",
        "            tmp_fixed_image.CopyInformation(fixed_image)\n",
        "            \n",
        "            numpy_moving_image = sitk.GetArrayFromImage(moving_image)\n",
        "            numpy_moving_image = ndimage.gaussian_filter(numpy_moving_image,\n",
        "                                                         sigma=(gaussian_sigma[i] / 2,\n",
        "                                                                gaussian_sigma[i],\n",
        "                                                                gaussian_sigma[i]),\n",
        "                                                         mode='constant')\n",
        "            \n",
        "            tmp_moving_image = sitk.GetImageFromArray(numpy_moving_image)\n",
        "            tmp_moving_image.CopyInformation(moving_image)\n",
        "            \n",
        "    \n",
        "            transform, metric = Registration._parallel_register(sitk.AffineTransform(transform),\n",
        "                                                                tmp_moving_image, tmp_fixed_image,\n",
        "                                                                learning_rate_list[i], histogram_bins,\n",
        "                                                                sampling_rate, seed)\n",
        "        \n",
        "            if debug_output > 0:\n",
        "                debug_image = sitk.Resample(tmp_moving_image,\n",
        "                                            tmp_fixed_image,\n",
        "                                            transform,\n",
        "                                            sitk.sitkLinear,\n",
        "                                            0.0,\n",
        "                                            tmp_moving_image.GetPixelID())\n",
        "                debug_image_moving.append(debug_image)\n",
        "                debug_image_fixed.append(tmp_fixed_image)\n",
        "    \n",
        "    \n",
        "        \n",
        "        final_transform = transform\n",
        "        \n",
        "        debug_image_outputs = [debug_image_moving, debug_image_fixed]\n",
        "        \n",
        "        if debug_output == 1:\n",
        "            return final_transform, metric, debug_image_outputs\n",
        "        else:\n",
        "            return final_transform, metric\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def _minor_alignment(moving_image: sitk.Image, fixed_image: sitk.Image,\n",
        "                         debug_output: int=0) -> Tuple[sitk.Transform, float]:\n",
        "        debug_image_outputs = []\n",
        "        debug_image_moving = []\n",
        "        debug_image_fixed = []\n",
        "        \n",
        "        sitk.ProcessObject.SetGlobalDefaultNumberOfThreads(1)\n",
        "        \n",
        "        initial_transform = sitk.AffineTransform(3)\n",
        "        \n",
        "        if debug_output > 0:\n",
        "            debug_image = sitk.Resample(moving_image,\n",
        "                                        fixed_image,\n",
        "                                        initial_transform,\n",
        "                                        sitk.sitkLinear,\n",
        "                                        0.0,\n",
        "                                        moving_image.GetPixelID())\n",
        "            debug_image_moving.append(debug_image)\n",
        "            debug_image_fixed.append(fixed_image)\n",
        "        \n",
        "        \n",
        "        transform = initial_transform\n",
        "        \n",
        "        \n",
        "        gaussian_sigma = [2, 1, 0]\n",
        "        \n",
        "        histogram_bins = 200\n",
        "        learning_rate_list = [[2.0, 2.0, 1.0, 0.5, None],\n",
        "                              [2.0, 1.0, 0.5, 0.25, None],\n",
        "                              [1.0, 0.5, 0.25, 0.1, None],]\n",
        "        sampling_rate = 1.0\n",
        "        \n",
        "        seed =  12453\n",
        "        \n",
        "        for i in range(len(gaussian_sigma)):\n",
        "                \n",
        "            numpy_fixed_image = sitk.GetArrayFromImage(fixed_image)    \n",
        "            numpy_fixed_image = ndimage.gaussian_filter(numpy_fixed_image,\n",
        "                                                        sigma=(1,\n",
        "                                                               gaussian_sigma[i],\n",
        "                                                               gaussian_sigma[i]),\n",
        "                                                        mode='constant')\n",
        "            \n",
        "            \n",
        "            tmp_fixed_image = sitk.GetImageFromArray(numpy_fixed_image)\n",
        "            tmp_fixed_image.CopyInformation(fixed_image)\n",
        "            \n",
        "            numpy_moving_image = sitk.GetArrayFromImage(moving_image)\n",
        "            numpy_moving_image = ndimage.gaussian_filter(numpy_moving_image,\n",
        "                                                         sigma=(gaussian_sigma[i] / 2,\n",
        "                                                                gaussian_sigma[i],\n",
        "                                                                gaussian_sigma[i]),\n",
        "                                                         mode='constant')\n",
        "            \n",
        "            tmp_moving_image = sitk.GetImageFromArray(numpy_moving_image)\n",
        "            tmp_moving_image.CopyInformation(moving_image)\n",
        "    \n",
        "            transform, metric = Registration._parallel_register(sitk.AffineTransform(transform),\n",
        "                                                                tmp_moving_image, tmp_fixed_image,\n",
        "                                                                learning_rate_list[i], histogram_bins,\n",
        "                                                                sampling_rate, seed)\n",
        "        \n",
        "            if debug_output > 0:\n",
        "                debug_image = sitk.Resample(tmp_moving_image,\n",
        "                                            tmp_fixed_image,\n",
        "                                            transform,\n",
        "                                            sitk.sitkLinear,\n",
        "                                            0.0,\n",
        "                                            tmp_moving_image.GetPixelID())\n",
        "                debug_image_moving.append(debug_image)\n",
        "                debug_image_fixed.append(tmp_fixed_image)\n",
        "    \n",
        "        \n",
        "        final_transform = transform\n",
        "        \n",
        "        debug_image_outputs = [debug_image_moving, debug_image_fixed]\n",
        "        \n",
        "        if debug_output == 1:\n",
        "            return final_transform, metric, debug_image_outputs\n",
        "        else:\n",
        "            return final_transform, metric\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def register(moving_image: sitk.Image, fixed_image: sitk.Image,\n",
        "                 debug_output: int=0) -> Tuple[sitk.Transform, float, Union[None, List[List[sitk.Image]]]]:        \n",
        "        major_output = Registration._major_alignment(moving_image, fixed_image, debug_output)\n",
        "        minor_output = Registration._minor_alignment(moving_image, fixed_image, debug_output)\n",
        "\n",
        "        if major_output[1] < minor_output[1]:\n",
        "            return major_output\n",
        "        else:\n",
        "            return minor_output\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def get_affine_matrix(image: sitk.Image) -> np.ndarray:\n",
        "        # get affine transform in LPS\n",
        "        c = [image.TransformContinuousIndexToPhysicalPoint(p)\n",
        "             for p in ((1, 0, 0),\n",
        "                       (0, 1, 0),\n",
        "                       (0, 0, 1),\n",
        "                       (0, 0, 0))]\n",
        "        c = np.array(c)\n",
        "        affine = np.concatenate([\n",
        "            np.concatenate([c[0:3] - c[3:], c[3:]], axis=0),\n",
        "            [[0.], [0.], [0.], [1.]]\n",
        "        ], axis=1)\n",
        "        affine = np.transpose(affine)\n",
        "        # convert to RAS to match nibabel etc.\n",
        "        affine = np.matmul(np.diag([-1., -1., 1., 1.]), affine)\n",
        "        return affine\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def get_affine_registration_matrix(moving_image: sitk.Image,\n",
        "                                       registration_affine: sitk.Transform) -> np.ndarray:\n",
        "        # Get affine transform in LPS\n",
        "        c = [registration_affine.TransformPoint(\n",
        "                 moving_image.TransformContinuousIndexToPhysicalPoint(p))\n",
        "             for p in ((1, 0, 0),\n",
        "                       (0, 1, 0),\n",
        "                       (0, 0, 1),\n",
        "                       (0, 0, 0))]\n",
        "        c = np.array(c)\n",
        "        affine = np.concatenate([\n",
        "            np.concatenate([c[0:3] - c[3:], c[3:]], axis=0),\n",
        "            [[0.], [0.], [0.], [1.]]\n",
        "        ], axis=1)\n",
        "        affine = np.transpose(affine)\n",
        "        # Convert to RAS to match nibabel etc.\n",
        "        affine = np.matmul(np.diag([-1., -1., 1., 1.]), affine)\n",
        "        return affine\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV9KwNnkjY_V"
      },
      "source": [
        "src/data/loader.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL1GULe7jRfJ"
      },
      "source": [
        "import os\n",
        "\n",
        "from enum import Enum\n",
        "\n",
        "from typing import Any, Dict, Tuple, List, Union\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import SimpleITK as sitk\n",
        "\n",
        "\n",
        "class FileType(Enum):\n",
        "    sa_ed = 'SA_ED'\n",
        "    sa_ed_gt = 'SA_ED_gt'\n",
        "    sa_es = 'SA_ES'\n",
        "    sa_es_gt = 'SA_ES_gt'\n",
        "    la_ed = 'LA_ED'\n",
        "    la_ed_gt = 'LA_ED_gt'\n",
        "    la_es = 'LA_ES'\n",
        "    la_es_gt = 'LA_ES_gt'\n",
        "    \n",
        "    \n",
        "class ExtraType(Enum):\n",
        "    reg_affine = 'SA_to_LA_registration_affine'\n",
        "    \n",
        "\n",
        "class OutputAffine(Enum):\n",
        "    sa_affine = 'SA_Affine'\n",
        "    la_affine = 'LA_Affine'    \n",
        "    \n",
        "\n",
        "class DataGenerator():\n",
        "\n",
        "    \n",
        "    def __init__(self, floating_precision: str = '32') -> None:\n",
        "        #file_path = Path(__file__).parent.absolute()\n",
        "        #expected_data_directory = os.path.join('..', '..', 'data')\n",
        "        \n",
        "        #self.data_directory = Path(os.path.join(file_path, expected_data_directory))\n",
        "        #self.cache_directory = os.path.join('..', '..', 'data_cache')\n",
        "        #self.cache_directory = Path(os.path.join(file_path, self.cache_directory))\n",
        "        self.data_directory = path_to_data_cache\n",
        "        self.cache_directory = path_to_data_cache\n",
        "\n",
        "        self.train_directory = Path(os.path.join(self.data_directory, 'training'))\n",
        "        # For the purposes of model development, the 'validation' set is treated\n",
        "        # as the test set\n",
        "        # (It does not have ground truth - validated on submission only)\n",
        "        self.testing_directory = Path(os.path.join(self.data_directory, 'validation'))\n",
        "        \n",
        "        self.train_list = self.get_patient_list(self.train_directory)\n",
        "        self.train_list = self.randomise_list(self.train_list, seed=4516, inplace=True)\n",
        "        self.train_list, self.validation_list = self.split_list(self.train_list, split_fraction=0.8)\n",
        "        self.test_list = self.get_patient_list(self.testing_directory)\n",
        "        \n",
        "        self.target_spacing = (1.25, 1.25, 10)\n",
        "        self.target_size = (160, 160, 17)\n",
        "        \n",
        "        self.n_classes = 4  # Including background\n",
        "\n",
        "        self.floating_precision = floating_precision\n",
        "        \n",
        "        # Compute the shape for the inputs and outputs\n",
        "        self.sa_target_shape = list(self.target_size)\n",
        "        self.sa_shape = self.sa_target_shape.copy()\n",
        "        self.sa_target_shape.append(self.n_classes)\n",
        "        \n",
        "        self.la_target_shape = list(self.target_size)\n",
        "        self.la_shape = self.la_target_shape.copy()\n",
        "        self.la_shape[-1] = 1\n",
        "        self.la_target_shape[-1] = self.n_classes\n",
        "        \n",
        "        self.affine_shape = (4, 4)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_patient_list(root_directory: Union[str, Path]) -> List[Path]:\n",
        "        files = glob(os.path.join(root_directory, \"**\"))\n",
        "        files = [Path(i) for i in files]\n",
        "        \n",
        "        return files\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def randomise_list(item_list: List[Any], seed: Union[None, int]=None,\n",
        "                       inplace: bool=True) -> List[Any]:\n",
        "        if not inplace:\n",
        "            item_list = item_list.copy()\n",
        "            \n",
        "        random_generator = np.random.RandomState(seed)\n",
        "        random_generator.shuffle(item_list)\n",
        "        \n",
        "        return item_list\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def split_list(item_list: List[Any], split_fraction: float) -> Tuple[List[Any]]:\n",
        "        assert 0 < split_fraction < 1\n",
        "        \n",
        "        split_index = int(len(item_list) * split_fraction)\n",
        "        \n",
        "        split_1 = item_list[:split_index]\n",
        "        split_2 = item_list[split_index:]\n",
        "                \n",
        "        return split_1, split_2\n",
        "\n",
        "        \n",
        "    @staticmethod\n",
        "    def load_image(patient_directory: Union[str, Path], file_type: FileType) -> sitk.Image:\n",
        "        file_suffix = '*' + file_type.value + '.nii.gz'\n",
        "        \n",
        "        file_path = os.path.join(patient_directory, file_suffix)\n",
        "        file_path = glob(file_path)\n",
        "        assert len(file_path) == 1\n",
        "        file_path = file_path[0]\n",
        "        \n",
        "        sitk_image = sitk.ReadImage(file_path)\n",
        "        \n",
        "        return sitk_image\n",
        "    \n",
        "    @staticmethod\n",
        "    def load_transformation(patient_directory: Union[str, Path], file_type: ExtraType) -> sitk.Transform:\n",
        "        file_suffix = '*' + file_type.value + '.tfm'\n",
        "        \n",
        "        file_path = os.path.join(patient_directory, file_suffix)\n",
        "        file_path = glob(file_path)\n",
        "        assert len(file_path) == 1\n",
        "        file_path = file_path[0]\n",
        "        \n",
        "        sitk_transform = sitk.ReadTransform(file_path)\n",
        "        \n",
        "        return sitk_transform\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def load_patient_data(patient_directory: Union[str, Path], has_gt: bool = True) -> Dict[str, sitk.Image]:\n",
        "        patient_data = {}\n",
        "        \n",
        "        patient_data[FileType.sa_ed.value] = DataGenerator.load_image(patient_directory, FileType.sa_ed)        \n",
        "        patient_data[FileType.sa_es.value] = DataGenerator.load_image(patient_directory, FileType.sa_es)        \n",
        "        patient_data[FileType.la_ed.value] = DataGenerator.load_image(patient_directory, FileType.la_ed)\n",
        "        patient_data[FileType.la_es.value] = DataGenerator.load_image(patient_directory, FileType.la_es)\n",
        "        \n",
        "        if has_gt:\n",
        "            patient_data[FileType.sa_ed_gt.value] = DataGenerator.load_image(patient_directory, FileType.sa_ed_gt)\n",
        "            patient_data[FileType.sa_es_gt.value] = DataGenerator.load_image(patient_directory, FileType.sa_es_gt)\n",
        "            patient_data[FileType.la_ed_gt.value] = DataGenerator.load_image(patient_directory, FileType.la_ed_gt)\n",
        "            patient_data[FileType.la_es_gt.value] = DataGenerator.load_image(patient_directory, FileType.la_es_gt)\n",
        "            \n",
        "        \n",
        "        return patient_data\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def load_extra_patient_data(patient_directory: Union[str, Path],\n",
        "                                patient_data: Dict[str, sitk.Image]) -> Dict[str, sitk.Image]:\n",
        "        \n",
        "        patient_data[ExtraType.reg_affine.value] = DataGenerator.load_transformation(patient_directory,\n",
        "                                                                                     ExtraType.reg_affine)\n",
        "        \n",
        "        return patient_data\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def preprocess_patient_data(patient_data: Dict[str, sitk.Image], spacing: Tuple[float],\n",
        "                                size: Tuple[int], has_gt: bool = True, register: bool = True) -> Dict[str, sitk.Image]:\n",
        "        # Resample images to standardised spacing and size\n",
        "        # Short-axis\n",
        "        patient_data[FileType.sa_ed.value] = Preprocess.resample_image(patient_data[FileType.sa_ed.value],\n",
        "                                                                       spacing, size, is_label=False)\n",
        "        patient_data[FileType.sa_es.value] = Preprocess.resample_image(patient_data[FileType.sa_es.value],\n",
        "                                                                       spacing, size, is_label=False)\n",
        "        if has_gt:\n",
        "            patient_data[FileType.sa_ed_gt.value] = Preprocess.resample_image(patient_data[FileType.sa_ed_gt.value],\n",
        "                                                                              spacing, size, is_label=True)\n",
        "            patient_data[FileType.sa_es_gt.value] = Preprocess.resample_image(patient_data[FileType.sa_es_gt.value],\n",
        "                                                                              spacing, size, is_label=True)\n",
        "\n",
        "        # Long-axis\n",
        "        la_spacing = list(spacing)\n",
        "        la_spacing[2] = patient_data[FileType.la_ed.value].GetSpacing()[2]\n",
        "        la_size = list(size)\n",
        "        la_size[2] = 1\n",
        "        patient_data[FileType.la_ed.value] = Preprocess.resample_image(patient_data[FileType.la_ed.value],\n",
        "                                                                       la_spacing, la_size, is_label=False)\n",
        "        patient_data[FileType.la_es.value] = Preprocess.resample_image(patient_data[FileType.la_es.value],\n",
        "                                                                       la_spacing, la_size, is_label=False)\n",
        "        if has_gt:\n",
        "            patient_data[FileType.la_ed_gt.value] = Preprocess.resample_image(patient_data[FileType.la_ed_gt.value],\n",
        "                                                                              la_spacing, la_size, is_label=True)\n",
        "            patient_data[FileType.la_es_gt.value] = Preprocess.resample_image(patient_data[FileType.la_es_gt.value],\n",
        "                                                                              la_spacing, la_size, is_label=True)\n",
        "        \n",
        "        # Register short-axis to long axis (only for end diastolic for faster execution time)\n",
        "        if register:\n",
        "            affine_transform, _ = Registration.register(patient_data[FileType.sa_ed.value],\n",
        "                                                        patient_data[FileType.la_ed.value])\n",
        "            patient_data[ExtraType.reg_affine.value] = affine_transform\n",
        "        \n",
        "        # Normalise intensities so there are (roughly) [0-1]\n",
        "        patient_data[FileType.sa_ed.value] = Preprocess.normalise_intensities(patient_data[FileType.sa_ed.value])\n",
        "        patient_data[FileType.sa_es.value] = Preprocess.normalise_intensities(patient_data[FileType.sa_es.value])\n",
        "        \n",
        "        patient_data[FileType.la_ed.value] = Preprocess.normalise_intensities(patient_data[FileType.la_ed.value])\n",
        "        patient_data[FileType.la_es.value] = Preprocess.normalise_intensities(patient_data[FileType.la_es.value])\n",
        "        \n",
        "        return patient_data\n",
        "        \n",
        "\n",
        "    def get_cache_directory(self, patient_directory: Union[str, Path]) -> Path:\n",
        "        path = os.path.normpath(patient_directory)\n",
        "        split_path = path.split(os.sep)\n",
        "        # .. / data / training or vlaidation / patient ID\n",
        "        # only last two are of interest\n",
        "        cache_directory = Path(os.path.join(self.cache_directory,\n",
        "                                            split_path[-2],\n",
        "                                            split_path[-1]))\n",
        "        \n",
        "        return cache_directory\n",
        "\n",
        "    \n",
        "    def is_cached(self, patient_directory: Union[str, Path], has_gt: bool = True) -> bool:\n",
        "        patient_cache_directory = self.get_cache_directory(patient_directory)\n",
        "        \n",
        "        # Check if folder exists\n",
        "        if os.path.isdir(patient_cache_directory):\n",
        "            # and every individual file exist\n",
        "            for expected_file_name in FileType:\n",
        "                if not has_gt and expected_file_name.value.endswith('_gt'):\n",
        "                    continue\n",
        "                expected_file_path = os.path.join(patient_cache_directory,\n",
        "                                                  expected_file_name.value + '.nii.gz')\n",
        "                if not os.path.exists(expected_file_path):\n",
        "                    return False\n",
        "                \n",
        "            for expected_file_name in ExtraType:\n",
        "                expected_file_path = os.path.join(patient_cache_directory,\n",
        "                                                  expected_file_name.value + '.tfm')\n",
        "                if not os.path.exists(expected_file_path):\n",
        "                    return False\n",
        "            return True\n",
        "        \n",
        "        return False\n",
        "\n",
        "        \n",
        "    def save_cache(self, patient_directory: Union[str, Path],\n",
        "                    patient_data: Dict[str, sitk.Image]) -> None:\n",
        "        patient_cache_directory = self.get_cache_directory(patient_directory)\n",
        "        os.makedirs(patient_cache_directory, exist_ok=True)\n",
        "        \n",
        "        for key, data in patient_data.items():\n",
        "            if key in (k.value for k in FileType):\n",
        "                file_path = os.path.join(patient_cache_directory, key + '.nii.gz')\n",
        "                sitk.WriteImage(data, file_path)\n",
        "            elif key in (k.value for k in ExtraType):\n",
        "                file_path = os.path.join(patient_cache_directory, key + '.tfm')\n",
        "                sitk.WriteTransform(data, file_path)\n",
        "        \n",
        "    \n",
        "    def load_cache(self, patient_directory: Union[str, Path], has_gt: bool = True) -> Dict[str, sitk.Image]:\n",
        "        patient_cache_directory = self.get_cache_directory(patient_directory)\n",
        "        patient_data = self.load_patient_data(patient_cache_directory, has_gt)\n",
        "        patient_data = self.load_extra_patient_data(patient_cache_directory, patient_data)\n",
        "        \n",
        "        return patient_data\n",
        "    \n",
        "    \n",
        "    def to_numpy(self, patient_data: Dict[str, sitk.Image], has_affine_matrix: bool) -> Dict[str, np.ndarray]:\n",
        "        \n",
        "        # Handle 'ExtraType' data first\n",
        "        if has_affine_matrix:\n",
        "            sa_affine = Registration.get_affine_registration_matrix(patient_data[FileType.sa_ed.value],\n",
        "                                                                    patient_data[ExtraType.reg_affine.value])\n",
        "            sa_affine = sa_affine.astype(np.float32)\n",
        "            la_affine = Registration.get_affine_matrix(patient_data[FileType.la_ed.value])\n",
        "            la_affine = la_affine.astype(np.float32)\n",
        "        \n",
        "        # Free from memory (and indexing)\n",
        "        del patient_data[ExtraType.reg_affine.value]\n",
        "        \n",
        "        # Handle original file data (images and segmentations)\n",
        "        for key, image in patient_data.items():\n",
        "            numpy_image = sitk.GetArrayFromImage(image)\n",
        "            # Swap axes so ordering is x, y, z rather than z, y, x as stored\n",
        "            # in sitk\n",
        "            numpy_image = np.swapaxes(numpy_image, 0, -1)\n",
        "            \n",
        "            # Generate one-hot encoding of the labels\n",
        "            if 'gt' in key:\n",
        "                numpy_image = numpy_image.astype(np.uint8)\n",
        "                if 'LA' in key: # use the 'depth; axis as the channel for the label\n",
        "                    numpy_image = np.squeeze(numpy_image, axis=-1)\n",
        "                n_values = self.n_classes\n",
        "                numpy_image = np.eye(n_values)[numpy_image]\n",
        "            \n",
        "            \n",
        "            if self.floating_precision == '16':\n",
        "                numpy_image = numpy_image.astype(np.float16)\n",
        "            else:\n",
        "                numpy_image = numpy_image.astype(np.float32)\n",
        "                \n",
        "            # Add 'channel' axis for 3D images\n",
        "            #if 'sa' in key:\n",
        "            #    numpy_image = np.expand_dims(numpy_image, axis=-1)\n",
        "                \n",
        "            patient_data[key] = numpy_image\n",
        "        \n",
        "        if has_affine_matrix:\n",
        "            patient_data[OutputAffine.sa_affine.value] = sa_affine\n",
        "            patient_data[OutputAffine.la_affine.value] = la_affine\n",
        "        \n",
        "        return patient_data\n",
        "    \n",
        "    @staticmethod\n",
        "    def to_structure(patient_data: Dict[str, sitk.Image], has_affine_matrix: bool,\n",
        "                     has_gt: bool = True):\n",
        "        output_data = []\n",
        "        if has_gt:\n",
        "            output_data.append(({'input_sa': patient_data[FileType.sa_ed.value],\n",
        "                                 'input_la': patient_data[FileType.la_ed.value]},\n",
        "                                {'output_sa': patient_data[FileType.sa_ed_gt.value],\n",
        "                                 'output_la': patient_data[FileType.la_ed_gt.value]}))\n",
        "            \n",
        "            output_data.append(({'input_sa': patient_data[FileType.sa_es.value],\n",
        "                                 'input_la': patient_data[FileType.la_es.value]},\n",
        "                                {'output_sa': patient_data[FileType.sa_es_gt.value],\n",
        "                                 'output_la': patient_data[FileType.la_es_gt.value]}))\n",
        "        else:\n",
        "            output_data.append(({'input_sa': patient_data[FileType.sa_ed.value],\n",
        "                                 'input_la': patient_data[FileType.la_ed.value]},))\n",
        "            \n",
        "            output_data.append(({'input_sa': patient_data[FileType.sa_es.value],\n",
        "                                 'input_la': patient_data[FileType.la_es.value]},))\n",
        "            \n",
        "        if has_affine_matrix:\n",
        "            for data in output_data:\n",
        "                data[0]['input_sa_affine'] = patient_data[OutputAffine.sa_affine.value]\n",
        "                data[0]['input_la_affine'] = patient_data[OutputAffine.la_affine.value]\n",
        "                \n",
        "        return output_data\n",
        "        \n",
        "\n",
        "    def generator(self, patient_directory: Union[str, Path], affine_matrix: bool,\n",
        "                  has_gt: bool = True) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        if self.is_cached(patient_directory, has_gt):\n",
        "            patient_data = self.load_cache(patient_directory, has_gt)\n",
        "        else:\n",
        "            patient_data = DataGenerator.load_patient_data(patient_directory, has_gt)\n",
        "            patient_data = DataGenerator.preprocess_patient_data(patient_data,\n",
        "                                                                 self.target_spacing,\n",
        "                                                                 self.target_size,\n",
        "                                                                 has_gt,\n",
        "                                                                 affine_matrix)\n",
        "            self.save_cache(patient_directory, patient_data)\n",
        "\n",
        "        \n",
        "        patient_data = self.to_numpy(patient_data, affine_matrix)\n",
        "    \n",
        "        output_data = self.to_structure(patient_data, affine_matrix, has_gt)\n",
        "        return output_data\n",
        "\n",
        "    \n",
        "    def sitk_generator(self, patient_directory: Union[str, Path], has_gt: bool = True) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        \"\"\"\n",
        "        Returns pre- and post-processed data in sitk\n",
        "        \"\"\"\n",
        "        if self.is_cached(patient_directory, has_gt):\n",
        "            pre_patient_data = DataGenerator.load_patient_data(patient_directory, has_gt)\n",
        "            post_patient_data = self.load_cache(patient_directory, has_gt)\n",
        "        else:\n",
        "            pre_patient_data = DataGenerator.load_patient_data(patient_directory, has_gt)\n",
        "            post_patient_data = DataGenerator.load_patient_data(patient_directory, has_gt)\n",
        "            post_patient_data = DataGenerator.preprocess_patient_data(post_patient_data,\n",
        "                                                                      self.target_spacing,\n",
        "                                                                      self.target_size,\n",
        "                                                                      has_gt,\n",
        "                                                                      False)\n",
        "            self.save_cache(patient_directory, pre_patient_data)\n",
        "            \n",
        "        \n",
        "        pre_output_data = self.to_structure(pre_patient_data, False, has_gt)\n",
        "        post_output_data = self.to_structure(post_patient_data, False, has_gt)\n",
        "        \n",
        "        return pre_output_data, post_output_data\n",
        "        \n",
        "        \n",
        "    def train_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.train_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=False)\n",
        "            \n",
        "            yield patient_data[0]   # End diastolic\n",
        "            yield patient_data[1]   # End systolic\n",
        "        \n",
        "    \n",
        "    def validation_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.validation_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=False)\n",
        "            \n",
        "            yield patient_data[0]\n",
        "            yield patient_data[1]\n",
        "            \n",
        "    \n",
        "    def test_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.test_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=False)\n",
        "            \n",
        "            yield patient_data[0]\n",
        "            yield patient_data[1]\n",
        "            \n",
        "    \n",
        "    def test_generator_inference(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.test_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=False, has_gt=False)\n",
        "            pre_patient_data, post_patient_data = self.sitk_generator(patient_directory, has_gt=False)\n",
        "            \n",
        "            yield patient_data[0], pre_patient_data[0], post_patient_data[0], patient_directory, 'ed'\n",
        "            yield patient_data[1], pre_patient_data[1], post_patient_data[1], patient_directory, 'es'\n",
        "        \n",
        "        \n",
        "    def train_affine_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.train_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=True)\n",
        "            \n",
        "            yield patient_data[0]   # End diastolic\n",
        "            yield patient_data[1]   # End systolic\n",
        "        \n",
        "    \n",
        "    def validation_affine_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.validation_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=True)\n",
        "            \n",
        "            yield patient_data[0]\n",
        "            yield patient_data[1]\n",
        "            \n",
        "    \n",
        "    def test_affine_generator(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.test_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=True)\n",
        "            \n",
        "            yield patient_data[0]\n",
        "            yield patient_data[1]\n",
        "\n",
        "\n",
        "    def test_affine_generator_inference(self, verbose: int = 0) -> Tuple[Dict[str, np.ndarray]]:\n",
        "        for patient_directory in self.test_list:\n",
        "            if verbose > 0:\n",
        "                print('Generating patient: ', patient_directory)\n",
        "            patient_data = self.generator(patient_directory, affine_matrix=True, has_gt=False)\n",
        "            pre_patient_data, post_patient_data = self.sitk_generator(patient_directory, has_gt=False)\n",
        "            \n",
        "            yield patient_data[0], pre_patient_data[0], post_patient_data[0], patient_directory, 'ed'\n",
        "            yield patient_data[1], pre_patient_data[1], post_patient_data[1], patient_directory, 'es'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv7FQFqgj1z1"
      },
      "source": [
        "src/data/tf_generator.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA5s4YjBj5ml"
      },
      "source": [
        "from typing import Dict, Tuple, Union\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class TensorFlowDataGenerator():\n",
        "    \n",
        "    @staticmethod\n",
        "    def _prepare_generators(dg: DataGenerator, use_affine: bool, batch_size: int,\n",
        "                            output_shapes: Tuple[Dict[str, tf.TensorShape]],\n",
        "                            output_types: Tuple[Dict[str, tf.dtypes.DType]],\n",
        "                            max_buffer_size: Union[int, None]=None,\n",
        "                            floating_precision: str='32') -> Tuple[tf.data.Dataset]:\n",
        "        \n",
        "        buffer_size = len(dg.train_list) * 2\n",
        "        if max_buffer_size is not None:\n",
        "            buffer_size = min(buffer_size, max_buffer_size)    \n",
        "\n",
        "        generator_type = dg.train_affine_generator if use_affine else dg.train_generator\n",
        "        train_generator = tf.data.Dataset.from_generator(generator_type,\n",
        "                                                         output_types=output_types,\n",
        "                                                         output_shapes=output_shapes)\n",
        "        train_generator = train_generator.shuffle(buffer_size=buffer_size,\n",
        "                                                  seed=4875,\n",
        "                                                  reshuffle_each_iteration=True\n",
        "                                                  ).batch(batch_size).prefetch(2)\n",
        "        \n",
        "        generator_type = dg.validation_affine_generator if use_affine else dg.validation_generator\n",
        "        validation_generator = tf.data.Dataset.from_generator(generator_type,\n",
        "                                                              output_types=output_types,\n",
        "                                                              output_shapes=output_shapes)\n",
        "        validation_generator = validation_generator.batch(batch_size)\n",
        "        \n",
        "        inference = False\n",
        "        if inference:\n",
        "            generator_type = dg.test_affine_generator_inference if use_affine else dg.test_generator_inference\n",
        "        else:\n",
        "            generator_type = dg.test_affine_generator if use_affine else dg.test_generator\n",
        "        test_generator = tf.data.Dataset.from_generator(generator_type,\n",
        "                                                        output_types=output_types)\n",
        "        test_generator = test_generator.batch(batch_size)\n",
        "        \n",
        "        return train_generator, validation_generator, test_generator, dg\n",
        "        \n",
        "    \n",
        "    @staticmethod\n",
        "    def get_generators(batch_size: int, max_buffer_size: Union[int, None]=None,\n",
        "                       floating_precision: str='32') -> Tuple[tf.data.Dataset]:\n",
        "        dg = DataGenerator(floating_precision)\n",
        "        \n",
        "        output_shapes = ({'input_sa': tf.TensorShape(dg.sa_shape),\n",
        "                          'input_la': tf.TensorShape(dg.la_shape)},\n",
        "                         {'output_sa': tf.TensorShape(dg.sa_target_shape),\n",
        "                          'output_la': tf.TensorShape(dg.la_target_shape)})\n",
        "        \n",
        "        if floating_precision == '16':\n",
        "            float_type = tf.float16\n",
        "        else:\n",
        "            float_type = tf.float32\n",
        "        # TODO: Change to dynamic input parameters\n",
        "        output_types = ({'input_sa': float_type,\n",
        "                         'input_la': float_type},\n",
        "                        {'output_sa': float_type,\n",
        "                         'output_la': float_type})\n",
        "\n",
        "        use_affine = False\n",
        "        return TensorFlowDataGenerator._prepare_generators(dg, use_affine, batch_size,\n",
        "                                                           output_shapes,\n",
        "                                                           output_types,\n",
        "                                                           max_buffer_size,\n",
        "                                                           floating_precision)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_affine_generators(batch_size: int, max_buffer_size: Union[int, None]=None,\n",
        "                              floating_precision: str='32') -> Tuple[tf.data.Dataset]:\n",
        "        dg = DataGenerator(floating_precision)\n",
        "        \n",
        "        output_shapes = ({'input_sa': tf.TensorShape(dg.sa_shape),\n",
        "                          'input_la': tf.TensorShape(dg.la_shape),\n",
        "                          'input_sa_affine': tf.TensorShape(dg.affine_shape),\n",
        "                          'input_la_affine': tf.TensorShape(dg.affine_shape)},\n",
        "                         {'output_sa': tf.TensorShape(dg.sa_target_shape),\n",
        "                          'output_la': tf.TensorShape(dg.la_target_shape)})\n",
        "        \n",
        "        if floating_precision == '16':\n",
        "            float_type = tf.float16\n",
        "        else:\n",
        "            float_type = tf.float32\n",
        "        # TODO: Change to dynamic input parameters\n",
        "        output_types = ({'input_sa': float_type,\n",
        "                         'input_la': float_type,\n",
        "                         'input_sa_affine': tf.float32,\n",
        "                         'input_la_affine': tf.float32},\n",
        "                        {'output_sa': float_type,\n",
        "                         'output_la': float_type})\n",
        "\n",
        "        use_affine = True\n",
        "        return TensorFlowDataGenerator._prepare_generators(dg, use_affine, batch_size,\n",
        "                                                           output_shapes,\n",
        "                                                           output_types,\n",
        "                                                           max_buffer_size,\n",
        "                                                           floating_precision)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coSsv-QwlDMO"
      },
      "source": [
        "src/tf/loasses.loss.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK35_MWllGgE"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Loss taken from here:\n",
        "#    https://github.com/tensorflow/models/blob/master/official/vision/keras_cv/losses/focal_loss.py\n",
        "class FocalLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"Implements a Focal loss for classification problems.\n",
        "    Reference:\n",
        "      [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 alpha,\n",
        "                 gamma,\n",
        "                 reduction=tf.keras.losses.Reduction.AUTO,\n",
        "                 name=None):\n",
        "        \"\"\"Initializes `FocalLoss`.\n",
        "        Args:\n",
        "          alpha: The `alpha` weight factor for binary class imbalance.\n",
        "          gamma: The `gamma` focusing parameter to re-weight loss.\n",
        "          reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to\n",
        "            loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n",
        "            option will be determined by the usage context. For almost all cases\n",
        "            this defaults to `SUM_OVER_BATCH_SIZE`. When used with\n",
        "            `tf.distribute.Strategy`, outside of built-in training loops such as\n",
        "            `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE`\n",
        "            will raise an error. Please see this custom training [tutorial](\n",
        "              https://www.tensorflow.org/tutorials/distribute/custom_training) for\n",
        "                more details.\n",
        "          name: Optional name for the op. Defaults to 'retinanet_class_loss'.\n",
        "        \"\"\"\n",
        "        self._alpha = alpha\n",
        "        self._gamma = gamma\n",
        "        super(FocalLoss, self).__init__(reduction=reduction, name=name)\n",
        "    \n",
        "    \n",
        "    def call(self, y_true, y_pred):\n",
        "        \"\"\"Invokes the `FocalLoss`.\n",
        "        Args:\n",
        "          y_true: A tensor of size [batch, num_anchors, num_classes]\n",
        "          y_pred: A tensor of size [batch, num_anchors, num_classes]\n",
        "        Returns:\n",
        "          Summed loss float `Tensor`.\n",
        "        \"\"\"\n",
        "        with tf.name_scope('focal_loss'):\n",
        "            y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "            y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "            positive_label_mask = tf.equal(y_true, 1.0)\n",
        "            cross_entropy = (\n",
        "                tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
        "            probs = tf.sigmoid(y_pred)\n",
        "            probs_gt = tf.where(positive_label_mask, probs, 1.0 - probs)\n",
        "            # With small gamma, the implementation could produce NaN during back prop.\n",
        "            modulator = tf.pow(1.0 - probs_gt, self._gamma)\n",
        "            loss = modulator * cross_entropy\n",
        "            weighted_loss = tf.where(positive_label_mask, self._alpha * loss,\n",
        "                                     (1.0 - self._alpha) * loss)\n",
        "        \n",
        "        return weighted_loss\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'alpha': self._alpha,\n",
        "            'gamma': self._gamma,\n",
        "        }\n",
        "        base_config = super(FocalLoss, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "\n",
        "class TverskyLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"Implements a Tversky loss for classification problems.\n",
        "    Reference:\n",
        "      [Tversky loss function for image segmentation using 3D fully convolutional\n",
        "       deep networks](https://arxiv.org/abs/1706.05721).\n",
        "      \n",
        "      'In the case of α=β=0.5 the Tversky index simplifies to be the same as\n",
        "       the Dice coefficient, which is also equal to the F1 score. With α=β=1,\n",
        "       Equation 2 produces Tanimoto coefficient, and setting α+β=1 produces\n",
        "       the set of Fβ scores. Larger βs weigh recall higher than precision (by\n",
        "       placing more emphasis on false negatives)'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 alpha,\n",
        "                 beta,\n",
        "                 reduction=tf.keras.losses.Reduction.AUTO,\n",
        "                 name=None):\n",
        "        \"\"\"Initializes `TverskyLoss`.\n",
        "        Args:\n",
        "          alpha: The `alpha` weight factor for binary class imbalance.\n",
        "          gamma: The `gamma` focusing parameter to re-weight loss.\n",
        "          reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to\n",
        "            loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n",
        "            option will be determined by the usage context. For almost all cases\n",
        "            this defaults to `SUM_OVER_BATCH_SIZE`. When used with\n",
        "            `tf.distribute.Strategy`, outside of built-in training loops such as\n",
        "            `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE`\n",
        "            will raise an error. Please see this custom training [tutorial](\n",
        "              https://www.tensorflow.org/tutorials/distribute/custom_training) for\n",
        "                more details.\n",
        "          name: Optional name for the op.\n",
        "        \"\"\"\n",
        "        self._alpha = alpha\n",
        "        self._beta = beta\n",
        "        super(TverskyLoss, self).__init__(reduction=reduction, name=name)\n",
        "  \n",
        "  \n",
        "    def call(self, y_true, y_pred):\n",
        "        \"\"\"Invokes the `TverskyLoss`.\n",
        "        Args:\n",
        "          y_true: A tensor of size [batch, ..., num_classes]\n",
        "          y_pred: A tensor of size [batch, ..., num_classes]\n",
        "        Returns:\n",
        "          Summed loss float `Tensor`.\n",
        "        \"\"\"\n",
        "        with tf.name_scope('tversky_loss'):\n",
        "            epsilon = 1e-6\n",
        "            y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "            y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "            \n",
        "            # TODO: softmax is unstable\n",
        "            y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
        "            \n",
        "            dim = tf.reduce_prod(tf.shape(y_true)[1:])\n",
        "            y_true_flatten = tf.reshape(y_true, [-1, dim])\n",
        "            y_pred_flatten = tf.reshape(y_pred, [-1, dim])\n",
        "            \n",
        "            tp = tf.math.reduce_sum(y_true_flatten * y_pred_flatten, axis=-1)\n",
        "            fp = tf.math.reduce_sum((1.0 - y_true_flatten) * y_pred_flatten, axis=-1)\n",
        "            fn = tf.math.reduce_sum(y_true_flatten * (1.0 - y_pred_flatten), axis=-1)\n",
        "            \n",
        "            tversky = (tp + epsilon) / (tp + self._alpha * fp + self._beta * fn + epsilon)\n",
        "            \n",
        "            loss = 1 - tf.reduce_mean(tversky)\n",
        "    \n",
        "        return loss\n",
        "  \n",
        "  \n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'alpha': self._alpha,\n",
        "            'beta': self._beta\n",
        "        }\n",
        "        base_config = super(TverskyLoss, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rbTKwB8lNP9"
      },
      "source": [
        "src/tf/metrics/metrics.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FsgC_DNlWHU"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "@tf.autograph.experimental.do_not_convert\n",
        "def dice(y_true, y_pred):\n",
        "    epsilon = 1e-6\n",
        "    \n",
        "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "    # Expected y_pred to be 'logits'\n",
        "    y_pred = tf.nn.softmax(y_pred)\n",
        "    \n",
        "    dim = tf.reduce_prod(tf.shape(y_true)[1:])\n",
        "    y_true_flatten = tf.reshape(y_true, [-1, dim])\n",
        "    y_pred_flatten = tf.reshape(y_pred, [-1, dim])\n",
        "\n",
        "    intersection = tf.math.reduce_sum(y_true_flatten * y_pred_flatten, axis=-1)\n",
        "    \n",
        "    union = tf.math.reduce_sum(y_true_flatten, axis=-1) + \\\n",
        "        tf.math.reduce_sum(y_pred_flatten, axis=-1)\n",
        "    \n",
        "    dice_coef = tf.math.reduce_mean((2. * intersection + epsilon) / (union + epsilon))\n",
        "\n",
        "    return dice_coef\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OwEpFVglYPk"
      },
      "source": [
        "src/tf/layers/transformer.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBaygLfJlevM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "from voxelmorph.tf.layers import SpatialTransformer\n",
        "\n",
        "\n",
        "class TargetAffineLayer(Layer):\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super(self.__class__, self).__init__(**kwargs)\n",
        "    \n",
        "    \n",
        "    @tf.autograph.experimental.do_not_convert\n",
        "    def _get_transformation(self, inputs):\n",
        "        image_affine = inputs[0]\n",
        "        target_affine = inputs[1]\n",
        "        \n",
        "        affine_transform = tf.cond(tf.reduce_all(tf.math.equal(target_affine, image_affine)),\n",
        "                                   lambda: tf.eye(4, dtype=image_affine.dtype),\n",
        "                                   lambda: tf.tensordot(tf.linalg.inv(image_affine),\n",
        "                                                        target_affine, axes=1))\n",
        "        \n",
        "        return affine_transform\n",
        "        \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "    \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "            inputs: list with four entries\n",
        "        \"\"\"\n",
        "        # check shapes\n",
        "        assert len(inputs) == 2, \"inputs has to be len 2, found: %d\" % len(inputs)\n",
        "        image_affine = tf.cast(inputs[0], dtype=tf.float32)\n",
        "        target_affine = tf.cast(inputs[1], dtype=tf.float32)\n",
        "        \n",
        "        affine_transform = tf.map_fn(self._get_transformation,\n",
        "                                     [image_affine, target_affine],\n",
        "                                     dtype=tf.float32)\n",
        "        \n",
        "        return affine_transform\n",
        "    \n",
        "\n",
        "\n",
        "class TargetShapePad(Layer):\n",
        "    \n",
        "    def __init__(self, image_shape, target_shape, **kwargs):\n",
        "        super(self.__class__, self).__init__(**kwargs)\n",
        "        \n",
        "        # TODO\n",
        "        #zero = tf.constant(0, dtype=tf.int32)\n",
        "        #self.paddings = [(zero, tf.math.maximum(tf.cast(target_shape[0] - image_shape[0], tf.int32), zero)),\n",
        "        #                 (zero, tf.math.maximum(tf.cast(target_shape[1] - image_shape[1], tf.int32), zero)),\n",
        "        #                 (zero, zero)]\n",
        "        self.paddings = [(0, 0),\n",
        "                         (0, 0),\n",
        "                         (0, 0)]\n",
        "        \n",
        "        self.init_config = {'image_shape': image_shape, 'target_shape': target_shape, **kwargs}\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        return self.init_config\n",
        "    \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        padded_image = tf.keras.layers.ZeroPadding3D(self.paddings)(inputs)\n",
        "\n",
        "        return padded_image\n",
        "\n",
        "\n",
        "\n",
        "class TargetShapeCrop(Layer):\n",
        "    \n",
        "    def __init__(self, image_shape, target_shape, **kwargs):\n",
        "        super(self.__class__, self).__init__(**kwargs)\n",
        "        \n",
        "        # TODO\n",
        "        #zero = tf.constant(0, dtype=tf.int32)\n",
        "        #self.cropping = [(zero, tf.math.maximum(tf.cast(image_shape[0] - target_shape[0], tf.int32), zero)),\n",
        "        #                 (zero, tf.math.maximum(tf.cast(image_shape[1] - target_shape[1], tf.int32), zero)),\n",
        "        #                 (zero, tf.math.maximum(tf.cast(image_shape[2] - target_shape[2], tf.int32), zero))]\n",
        "        self.cropping = [(0, 0),\n",
        "                         (0, 0),\n",
        "                         (0, 16)]\n",
        "        \n",
        "        self.init_config = {'image_shape': image_shape, 'target_shape': target_shape, **kwargs}\n",
        "        \n",
        "    \n",
        "    def get_config(self):\n",
        "        return self.init_config\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        cropped_image = tf.keras.layers.Cropping3D(self.cropping)(inputs)\n",
        "        \n",
        "        return cropped_image\n",
        "    \n",
        "    \n",
        "def spatial_target_transformer(x, affine_matrix, target_affine_matrix,\n",
        "                               image_shape, target_image_shape):\n",
        "    affine = TargetAffineLayer()([affine_matrix, target_affine_matrix])\n",
        "    \n",
        "    x = TargetShapePad(image_shape, target_image_shape)(x)\n",
        "    \n",
        "    original_dtype = x.dtype\n",
        "    x = tf.cast(x, dtype=tf.float32)\n",
        "    x = SpatialTransformer(interp_method='linear',\n",
        "                           indexing='ij',\n",
        "                           add_identity=False,\n",
        "                           shift_center=False,\n",
        "                           fill_value=0.0,\n",
        "                           dtype=tf.float32)([x, affine])\n",
        "    x = tf.cast(x, dtype=original_dtype)\n",
        "    \n",
        "    x = TargetShapeCrop(image_shape, target_image_shape)(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lks12hw8lked"
      },
      "source": [
        "src/tf/models/multi_stage_model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd4qQBWBlqBV"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#from tf.layers.transformer import spatial_target_transformer\n",
        "\n",
        "\n",
        "def _inception_block_a(x, num_filters, kernel_initializer, suffix, index):\n",
        "    # Branch 1\n",
        "    x1 = layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same',\n",
        "                             name=suffix + '_inception_a_max_pooling_1_1_' + index)(x)\n",
        "    x1 = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_a_conv2d_1_2_' + index)(x1)\n",
        "    x1 = layers.Activation('relu', name=suffix + '_inception_a_activation_1_3_' + index)(x1)\n",
        "    \n",
        "    # Branch 2\n",
        "    x2 = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_a_conv2d_2_1_' + index)(x)\n",
        "    x2 = layers.Activation('relu', name=suffix + '_inception_a_activation_2_2_' + index)(x2)\n",
        "    x2 = layers.Conv2D(num_filters // 2, (3, 3), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_a_conv2d_2_3_' + index)(x2)\n",
        "    x2 = layers.Activation('relu', name=suffix + '_inception_a_activation_2_4_' + index)(x2)\n",
        "    \n",
        "    # Branch 3\n",
        "    x3 = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_a_conv2d_3_1_' + index)(x)\n",
        "    x3 = layers.Activation('relu', name=suffix + '_inception_a_activation_3_2_' + index)(x3)\n",
        "    x3 = layers.Conv2D(num_filters // 2, (3, 3), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_a_conv2d_3_3_' + index)(x3)\n",
        "    x3 = layers.Activation('relu', name=suffix + '_inception_a_activation_3_4_' + index)(x3)\n",
        "    x3 = layers.Conv2D(num_filters // 2, (3, 3), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_a_conv2d_3_5_' + index)(x3)\n",
        "    x3 = layers.Activation('relu', name=suffix + '_inception_a_activation_3_6_' + index)(x3)\n",
        "    \n",
        "    # Branch 4\n",
        "    x4 = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_a_conv2d_4_1_' + index)(x)\n",
        "    x4 = layers.Activation('relu', name=suffix + '_inception_a_activation_4_2_' + index)(x4)\n",
        "    \n",
        "    # Concatenate branches\n",
        "    x = layers.Concatenate(axis=-1, name=suffix + '_inception_a_concatenate_' + index)([x, x1, x2, x3, x4])\n",
        "    # Reduce filter size\n",
        "    x = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      name=suffix + '_inception_a_conv2d_merge_' + index)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "def _inception_block_b(x, num_filters, kernel_initializer, suffix, index):\n",
        "    # Branch 1\n",
        "    x1 = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_b_conv2d_1_1_' + index)(x)\n",
        "    x1 = layers.Activation('relu', name=suffix + '_inception_b_activation_1_2_' + index)(x1)\n",
        "    \n",
        "    # Branch 2\n",
        "    x2 = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_b_conv2d_2_1_' + index)(x)\n",
        "    x2 = layers.Activation('relu', name=suffix + '_inception_b_activation_2_2_' + index)(x2)\n",
        "    x2 = layers.SeparableConv2D(num_filters // 2, (5, 5), (1, 1), padding='same',\n",
        "                                depthwise_initializer=kernel_initializer,\n",
        "                                pointwise_initializer=kernel_initializer,\n",
        "                                name=suffix + '_inception_b_seperable_conv2d_2_3_' + index)(x2)\n",
        "    x2 = layers.Activation('relu', name=suffix + '_inception_b_activation_2_4_' + index)(x2)\n",
        "    \n",
        "    # Branch 3\n",
        "    x3 = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_b_conv2d_3_1_' + index)(x)\n",
        "    x3 = layers.Activation('relu', name=suffix + '_inception_b_activation_3_2_' + index)(x3)\n",
        "    x3 = layers.Conv2D(num_filters // 2, (3, 3), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_b_conv2d_3_3_' + index)(x3)\n",
        "    x3 = layers.Activation('relu', name=suffix + '_inception_b_activation_3_4_' + index)(x3)\n",
        "    x3 = layers.SeparableConv2D(num_filters // 2, (7, 7), (1, 1), padding='same',\n",
        "                                depthwise_initializer=kernel_initializer,\n",
        "                                pointwise_initializer=kernel_initializer,\n",
        "                                name=suffix + '_inception_b_seperable_conv2d_3_5_' + index)(x3)\n",
        "    x3 = layers.Activation('relu', name=suffix + '_inception_b_activation_3_6_' + index)(x3)\n",
        "    \n",
        "    # Branch 3\n",
        "    x4 = layers.Conv2D(num_filters // 2, (1, 1), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_b_conv2d_4_1_' + index)(x)\n",
        "    x4 = layers.Activation('relu', name=suffix + '_inception_b_activation_4_2_' + index)(x4)\n",
        "    x4 = layers.Conv2D(num_filters // 2, (3, 3), (1, 1), padding='same',\n",
        "                       kernel_initializer=kernel_initializer,\n",
        "                       name=suffix + '_inception_b_conv2d_4_3_' + index)(x4)\n",
        "    x4 = layers.Activation('relu', name=suffix + '_inception_b_activation_4_4_' + index)(x4)\n",
        "    x4 = layers.SeparableConv2D(num_filters // 2, (9, 9), (1, 1), padding='same',\n",
        "                                depthwise_initializer=kernel_initializer,\n",
        "                                pointwise_initializer=kernel_initializer,\n",
        "                                name=suffix + '_inception_b_seperable_conv2d_4_5_' + index)(x4)\n",
        "    x4 = layers.Activation('relu', name=suffix + '_inception_b_activation_4_6_' + index)(x4)\n",
        "    \n",
        "    # Concatenate branches\n",
        "    x = layers.Concatenate(axis=-1, name=suffix + '_inception_b_concatenate_' + index)([x, x1, x2, x3, x4])\n",
        "    # Reduce filter size\n",
        "    x = layers.Conv2D(num_filters, (1, 1), (1, 1), padding='same',\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      name=suffix + '_inception_b_conv2d_merge_' + index)(x)\n",
        "    \n",
        "    return x\n",
        "    \n",
        "    \n",
        "def _shared_feature_pyramid_layers(num_pyramid_layers, input_shape, num_filters,\n",
        "                                   kernel_initializer, suffix, index):\n",
        "    shared_down_level = []\n",
        "    for i in range(num_pyramid_layers):\n",
        "        i_s = str(i + 1)\n",
        "        shared_layers = []\n",
        "        shared_layers.append(layers.Conv2D(num_filters, (3, 3), (1, 1), padding='same',\n",
        "                                           kernel_initializer=kernel_initializer,\n",
        "                                           name=suffix + '_pyramid_down_conv2d_' + i_s + '_1_' + index))\n",
        "        shared_layers.append(layers.Activation('relu', name=suffix + '_pyramid_down_activation_' + i_s + '_2_' + index))\n",
        "        shared_layers.append(layers.MaxPooling2D((2, 2), padding='same',\n",
        "                             name=suffix + '_pyramid_down_max_pooling_' + i_s + '_3_' + index))\n",
        "        x_pad_size = input_shape[0] // 4\n",
        "        y_pad_size = input_shape[1] // 4\n",
        "        shared_layers.append(layers.ZeroPadding2D((x_pad_size, y_pad_size),\n",
        "                             name=suffix + '_pyramid_down_padding_' + i_s + '_4_' + index))\n",
        "        \n",
        "        shared_down_level.append(shared_layers)\n",
        "    \n",
        "    \n",
        "    shared_up_level = []\n",
        "    for i in range(num_pyramid_layers):\n",
        "        i_s = str(i + 1)\n",
        "        shared_layers = []\n",
        "        shared_layers.append(layers.Conv2D(num_filters, (3, 3), (1, 1), padding='same',\n",
        "                                           kernel_initializer=kernel_initializer,\n",
        "                                           name=suffix + '_pyramid_up_conv2d_' + i_s + '_1_' + index))\n",
        "        shared_layers.append(layers.Activation('relu', name=suffix + '_pyramid_up_activation_' + i_s + '_2_' + index))\n",
        "        shared_layers.append(layers.UpSampling2D((2, 2), interpolation='bilinear',\n",
        "                                                 name=suffix + '_pyramid_upsampling_' + i_s + '_3_' + index))\n",
        "        x_crop_size = input_shape[0] // 2\n",
        "        y_crop_size = input_shape[1] // 2\n",
        "        shared_layers.append(layers.Cropping2D((x_crop_size, y_crop_size),\n",
        "                             name=suffix + '_pyramid_up_cropping_' + i_s + '_4_' + index))\n",
        "        \n",
        "        shared_up_level.append(shared_layers)\n",
        "    \n",
        "    \n",
        "    shared_skip = []\n",
        "    for i in range(num_pyramid_layers - 1):\n",
        "        i_s = str(i + 1)\n",
        "        shared_layers = []\n",
        "        shared_layers.append(layers.Conv2D(num_filters, (1, 1), (1, 1), padding='same',\n",
        "                                           kernel_initializer=kernel_initializer,\n",
        "                                           name=suffix + '_pyramid_skip_conv2d_' + i_s + '_1_' + index))\n",
        "        shared_layers.append(layers.Activation('relu', name=suffix + '_pyramid_skip_activation_' + i_s + '_2_' + index))\n",
        "        shared_layers.append(layers.Add(name=suffix + '_pyramid_skip_add_' + i_s + '_3_' + index))\n",
        "        \n",
        "        shared_skip.append(shared_layers)\n",
        "    \n",
        "    \n",
        "    return shared_down_level, shared_up_level, shared_skip\n",
        "\n",
        "    \n",
        "def feature_pyramid_layer(x, pyramid_layers, input_shape, num_filters, kernel_initializer,\n",
        "                          suffix, index):\n",
        "    \n",
        "    x_input = layers.Conv2D(num_filters, (1, 1), (1, 1), padding='same',\n",
        "                            kernel_initializer=kernel_initializer,\n",
        "                            name=suffix + '_pyramid_input_conv2d_1_' + index)(x)\n",
        "    x_input = layers.Activation('relu', name=suffix + '_pyramid_input_activation_2_' + index)(x_input)\n",
        "    \n",
        "\n",
        "    # Initialise shared layers for the pyramid\n",
        "    shared_down_level, shared_up_level, shared_skip = _shared_feature_pyramid_layers(pyramid_layers,\n",
        "                                                                                     input_shape,\n",
        "                                                                                     num_filters,\n",
        "                                                                                     kernel_initializer,\n",
        "                                                                                     suffix,\n",
        "                                                                                     index)\n",
        "    pyramid_output = []\n",
        "    \n",
        "    while True:\n",
        "        x_skip = []\n",
        "        x = x_input\n",
        "        # Downsampling\n",
        "        for i in range(pyramid_layers):\n",
        "            shared_layers = shared_down_level[i]\n",
        "            for j in range(len(shared_layers)):\n",
        "                x = shared_layers[j](x)\n",
        "            x_skip.append(x)        \n",
        "\n",
        "        # Remove last element, as last layer does not have a skip connection\n",
        "        del x_skip[-1]\n",
        "        x_skip.reverse()\n",
        "        \n",
        "        # Upsampling\n",
        "        \n",
        "        for i in range(pyramid_layers):\n",
        "            # Pass skip data and add with main data flow\n",
        "            if i > 0:\n",
        "                shared_skip_layers = shared_skip[i - 1]\n",
        "                x_s = x_skip[i - 1]\n",
        "                for s in range(len(shared_skip_layers) - 1):\n",
        "                    x_s = shared_skip_layers[s](x_s)\n",
        "                x = shared_skip_layers[-1]([x_s, x])\n",
        "            \n",
        "            shared_layers = shared_up_level[i]\n",
        "            for j in range(len(shared_layers)):\n",
        "                x = shared_layers[j](x)\n",
        "        \n",
        "                \n",
        "        pyramid_output.append(x)\n",
        "        \n",
        "        pyramid_layers -= 1\n",
        "        if pyramid_layers <= 0:\n",
        "            break\n",
        "    \n",
        "        \n",
        "    x = layers.Concatenate(axis=-1,\n",
        "                           name=suffix + '_pyramid_output_concatenate_1_' + index)(pyramid_output)\n",
        "    x = layers.Conv2D(num_filters, (1, 1), (1, 1), padding='same',\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      name=suffix + '_pyramid_output_conv2d_2_' + index)(x)\n",
        "    x = layers.Activation('relu', name=suffix + '_pyramid_output_activation_3_' + index)(x)\n",
        "        \n",
        "    return x\n",
        "        \n",
        "    \n",
        "def _shared_2d_branch(input_shape, kernel_initializer, downsample=False) -> keras.Model:\n",
        "    suffix = 'shared_branch'\n",
        "    \n",
        "    shared_input = keras.layers.Input(shape=input_shape, name='input_' + suffix)\n",
        "    \n",
        "    x = shared_input\n",
        "    \n",
        "    target_shape = input_shape\n",
        "    if downsample:\n",
        "        # Downsample image to reduce total memory requirement\n",
        "        original_dtype = x.dtype\n",
        "        target_shape = (input_shape[0] // 2, input_shape[1] //2)\n",
        "        x = tf.image.resize(x, target_shape, method=tf.image.ResizeMethod.BILINEAR,\n",
        "                            antialias=True, name=suffix + 'image_resize_down')\n",
        "        # Cast image back to original as 'resize' returns a Tensor of float32\n",
        "        x = tf.cast(x, original_dtype, name=suffix + 'image_casting_down')\n",
        "    \n",
        "    # Pass input through inception pipeline\n",
        "    x_inc = _inception_block_a(x, num_filters=32, kernel_initializer=kernel_initializer,\n",
        "                               suffix=suffix, index='1')\n",
        "    x_inc = _inception_block_a(x_inc, num_filters=64, kernel_initializer=kernel_initializer,\n",
        "                               suffix=suffix, index='2')\n",
        "    x_inc = _inception_block_a(x_inc, num_filters=64, kernel_initializer=kernel_initializer,\n",
        "                               suffix=suffix, index='3')\n",
        "    x_inc = _inception_block_b(x_inc, num_filters=128, kernel_initializer=kernel_initializer,\n",
        "                               suffix=suffix, index='4')\n",
        "    \n",
        "    # Pass input through multi-level feature pyramid pipeline\n",
        "    x_pyr = feature_pyramid_layer(x, pyramid_layers=3, input_shape=target_shape,\n",
        "                                  num_filters=128, kernel_initializer=kernel_initializer,\n",
        "                                  suffix=suffix, index='1')\n",
        "    \n",
        "    x = layers.Add(name=suffix + '_add_1')([x_inc, x_pyr])\n",
        "    \n",
        "    if downsample:\n",
        "        # Upsample image back to original resolution\n",
        "        target_shape = (input_shape[0], input_shape[1])\n",
        "        x = tf.image.resize(x, target_shape, method=tf.image.ResizeMethod.BILINEAR,\n",
        "                            name=suffix + 'image_resize_up')\n",
        "        x = tf.cast(x, original_dtype, name=suffix + 'image_casting_up')\n",
        "        \n",
        "    shared_model = keras.models.Model(shared_input, x)\n",
        "    return shared_model\n",
        "\n",
        "\n",
        "def get_model(sa_input_shape, la_input_shape, num_classes) -> keras.Model:\n",
        "    kernel_initializer = 'glorot_uniform'\n",
        "    \n",
        "    # The short-axis image is expected to have its 3rd dimension as channels: (B, W, H, C)    \n",
        "    input_sa = keras.Input(shape=sa_input_shape, name='input_sa')\n",
        "    input_la = keras.Input(shape=la_input_shape, name='input_la')\n",
        "    \n",
        "    input_sa_affine = keras.Input(shape=(4, 4), name='input_sa_affine', dtype=tf.float32)\n",
        "    input_la_affine = keras.Input(shape=(4, 4), name='input_la_affine', dtype=tf.float32)\n",
        "    \n",
        "    x_sa = input_sa\n",
        "    x_la = input_la\n",
        "    \n",
        "    \n",
        "    shared_layers = _shared_2d_branch(la_input_shape, kernel_initializer, downsample=False)\n",
        "        \n",
        "    # Create 'channel' axis that will be carried over when unstacking\n",
        "    x_sa = tf.expand_dims(x_sa, axis=-1)\n",
        "    # Break the 3D image into single 2D slice input\n",
        "    x_sa_list = tf.unstack(x_sa, axis=-2)\n",
        "    # Pass each slice to the shared layer    \n",
        "    for i in range(len(x_sa_list)):\n",
        "        x_sa_list[i] = shared_layers(x_sa_list[i])\n",
        "    \n",
        "    # Stack back into a 3D image (W, H, D, C)\n",
        "    x_sa = tf.stack(x_sa_list, axis=-2)\n",
        "    \n",
        "    # Short-Axis branch\n",
        "    x_sa = layers.Conv3D(32, (3, 3, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    x_sa = layers.Conv3D(32, (3, 3, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    x_sa = layers.Conv3D(64, (3, 3, 3), padding='same', kernel_initializer=kernel_initializer)(x_sa)\n",
        "    x_sa = layers.Activation('relu')(x_sa)\n",
        "    \n",
        "    output_sa = layers.Conv3D(num_classes, (1, 1, 1), padding='same',\n",
        "                              kernel_initializer=kernel_initializer, name='output_sa')(x_sa)\n",
        "    \n",
        "    # Pass the long-axis slice through the shared layers\n",
        "    x_la = shared_layers(x_la)\n",
        "    \n",
        "    # Long-Axis branch\n",
        "    x_la = layers.Conv2D(32, (3, 3), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    x_la = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    x_la = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "      \n",
        "    x_la = layers.Conv2D(num_classes, (1, 1), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    \n",
        "    # output_sa or x_sa as input to spatial transformer\n",
        "    x_la_t = spatial_target_transformer(output_sa, input_sa_affine, input_la_affine,\n",
        "                                        sa_input_shape, la_input_shape)\n",
        "    \n",
        "    # Reshape from 3d to 2d (depth size is expected to be 1 after the spatial transformer)\n",
        "    x_la_t = layers.Reshape((la_input_shape[0], la_input_shape[1], -1))(x_la_t)\n",
        "    \n",
        "    x_la = layers.Concatenate()([x_la, x_la_t])\n",
        "    \n",
        "    x_la = layers.Conv2D(32, (3, 3), padding='same', kernel_initializer=kernel_initializer)(x_la)\n",
        "    x_la = layers.Activation('relu')(x_la)\n",
        "    \n",
        "    output_la = layers.Conv2D(num_classes, (1, 1), padding='same',\n",
        "                              kernel_initializer=kernel_initializer, name='output_la')(x_la)\n",
        "    \n",
        "    model = keras.Model([input_sa, input_la, input_sa_affine, input_la_affine],\n",
        "                        [output_sa, output_la])\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um3DD7qRl5E4"
      },
      "source": [
        "src/configuration.py\\\n",
        "Use to select hyperparmaeter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr5lvs5Tl-_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af489fad-e614-4cf1-f81b-b55c835d303e"
      },
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "# Sortable version of HParam\n",
        "class HParamS(hp.HParam):\n",
        "    \n",
        "    def __init__(self, name, domain=None, display_name=None, description=None):\n",
        "        hp.HParam.__init__(self, name, domain, display_name, description)\n",
        "        \n",
        "    def __lt__(self, other):\n",
        "        return self.name.lower() < other.name.lower()\n",
        "\n",
        "\n",
        "class HyperParameters():\n",
        "    \n",
        "    def __init__(self, search_type: str):\n",
        "        # TODO: Load from file rather than hard-coded in this file\n",
        "        self.HP_FLOATING_POINT = HParamS('floating_point', hp.Discrete(['16']))\n",
        "        self.HP_XLA = HParamS('xla_compiler', hp.Discrete([False]))\n",
        "        self.HP_EPOCHS = HParamS('epochs', hp.Discrete([20]))\n",
        "        self.HP_BATCH_SIZE = HParamS('batch_size', hp.Discrete([1]))\n",
        "        self.HP_LEANRING_RATE = HParamS('learning_rate', hp.Discrete([0.0005]))\n",
        "        self.HP_OPTIMISER = HParamS('optimiser', hp.Discrete(['adam']))\n",
        "        self.HP_LOSS = HParamS('loss', hp.Discrete(['focal']))\n",
        "        self.HP_DROPOUT = HParamS('drop_out', hp.Discrete([0.0]))\n",
        "        \n",
        "        self.parameter_dict = {}\n",
        "        self.parameter_dict[self.HP_FLOATING_POINT] = self.HP_FLOATING_POINT.domain.values\n",
        "        self.parameter_dict[self.HP_XLA] = self.HP_XLA.domain.values\n",
        "        self.parameter_dict[self.HP_EPOCHS] = self.HP_EPOCHS.domain.values\n",
        "        self.parameter_dict[self.HP_BATCH_SIZE] = self.HP_BATCH_SIZE.domain.values\n",
        "        self.parameter_dict[self.HP_LEANRING_RATE] = self.HP_LEANRING_RATE.domain.values\n",
        "        self.parameter_dict[self.HP_OPTIMISER] = self.HP_OPTIMISER.domain.values\n",
        "        self.parameter_dict[self.HP_LOSS] = self.HP_LOSS.domain.values\n",
        "        self.parameter_dict[self.HP_DROPOUT] = self.HP_DROPOUT.domain.values\n",
        "        \n",
        "        if search_type == 'grid':\n",
        "            self.parameter_space = ParameterGrid(self.parameter_dict)\n",
        "        else:\n",
        "            raise ValueError('Invalid \\'search_type\\' input. Given: {}'.format(search_type))\n",
        "        \n",
        "        \n",
        "    def __iter__(self):\n",
        "        parameter_list = list(self.parameter_space)\n",
        "        for parameter in parameter_list:\n",
        "            yield parameter\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "if __name__ == '__main__':\n",
        "    config = HyperParameters(search_type='grid')\n",
        "    for i in config:\n",
        "        print(i)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nif __name__ == '__main__':\\n    config = HyperParameters(search_type='grid')\\n    for i in config:\\n        print(i)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ0BK0h-l0J8"
      },
      "source": [
        "src/run_training.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJa-PobZ2E4P"
      },
      "source": [
        "base_output_path = '/content/gdrive/MyDrive/mnms2_challenge/'   # Example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGxbkmNVlztv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "c7c6c413-35c6-4b65-ef62-771c86a7d8f7"
      },
      "source": [
        "import os\n",
        "\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "#from configuration import HyperParameters\n",
        "#from data import TensorFlowDataGenerator\n",
        "#from tf.models import test_model\n",
        "#from tf.losses.loss import FocalLoss, TverskyLoss\n",
        "#from tf.metrics.metrics import dice\n",
        "\n",
        "\n",
        "__SEED = 1456\n",
        "os.environ['PYTHONHASHSEED'] = str(__SEED)\n",
        "random.seed(__SEED)\n",
        "tf.random.set_seed(__SEED)\n",
        "np.random.seed(__SEED)\n",
        "\n",
        "\n",
        "def get_callbacks(prefix: str, checkpoint_directory: str, hparams):\n",
        "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_directory,\n",
        "        save_weights_only=False,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True)\n",
        "    \n",
        "    log_dir = os.path.join(base_output_path, 'logs', 'fit', prefix + datetime.datetime.now().strftime('_%Y%m%d-%H%M%S')) + '/'\n",
        "    #file_writer = tf.summary.create_file_writer(log_dir + '\\\\metrics')\n",
        "    #file_writer.set_as_default()\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    hparams_callback = hp.KerasCallback(log_dir, hparams)\n",
        "    \n",
        "    return [model_checkpoint_callback,\n",
        "            tensorboard_callback,\n",
        "            hparams_callback]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    hyper_parameters = HyperParameters('grid')\n",
        "    \n",
        "    for hparams in hyper_parameters:\n",
        "        keras.backend.clear_session()\n",
        "        \n",
        "        fp = hparams[hyper_parameters.HP_FLOATING_POINT]\n",
        "        if fp == '16':\n",
        "            policy = keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "            keras.mixed_precision.experimental.set_policy(policy)\n",
        "\n",
        "        use_xla = hparams[hyper_parameters.HP_XLA]\n",
        "        if use_xla:\n",
        "            tf.config.optimizer.set_jit('autoclustering')\n",
        "        \n",
        "        batch_size = hparams[hyper_parameters.HP_BATCH_SIZE]\n",
        "        (train_gen, validation_gen,\n",
        "         test_gen, data_gen) = TensorFlowDataGenerator.get_affine_generators(batch_size,\n",
        "                                                                             max_buffer_size=None,\n",
        "                                                                             floating_precision=fp)\n",
        "                                                                    \n",
        "        model = get_model(data_gen.sa_shape, data_gen.la_shape, data_gen.n_classes)\n",
        "        \n",
        "        learning_rate = hparams[hyper_parameters.HP_LEANRING_RATE]\n",
        "        if hparams[hyper_parameters.HP_OPTIMISER] == 'adam':\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "            \n",
        "        if hparams[hyper_parameters.HP_LOSS] == 'focal':\n",
        "            loss = FocalLoss(0.25, 2.0)\n",
        "        elif hparams[hyper_parameters.HP_LOSS] == 'tversky':\n",
        "            loss = TverskyLoss(0.5, 0.5)\n",
        "        elif hparams[hyper_parameters.HP_LOSS] == 'crossentropy':\n",
        "            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "            \n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=loss,\n",
        "            metrics=[dice])\n",
        "        \n",
        "        epochs = hparams[hyper_parameters.HP_EPOCHS]\n",
        "        prefix = 'multi_stage_model'\n",
        "        checkpoint_path = os.path.join(base_output_path, 'checkpoint', prefix + datetime.datetime.now().strftime('_%Y%m%d-%H%M%S')) + '/'\n",
        "        model.fit(x=train_gen,\n",
        "                  validation_data=validation_gen,\n",
        "                  epochs=epochs,\n",
        "                  callbacks=get_callbacks(prefix, checkpoint_path, hparams),\n",
        "                  verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
            "  Tesla K80, compute capability 3.7\n",
            "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
            "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "    115/Unknown - 889s 7s/step - loss: 0.0490 - output_sa_loss: 0.0172 - output_la_loss: 0.0318 - output_sa_dice: 0.7999 - output_la_dice: 0.6380"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3921dd4c8554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                   verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}